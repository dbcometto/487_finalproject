{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the file for Dataset 1, \"Covertype.\"  We will be classifying the type of trees in the forest based on the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful Variables\n",
    "mlp_filename = \"./models/mlp.pkl\"\n",
    "mlp1_filename = \"./models/mlp1.pkl\"\n",
    "mlp2_filename = \"./models/mlp2.pkl\"\n",
    "mlp3_filename = \"./models/mlp3.pkl\"\n",
    "\n",
    "lreg_filename = \"./models/lreg.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Wilderness_Area2</th>\n",
       "      <th>Wilderness_Area3</th>\n",
       "      <th>Wilderness_Area4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type34  Soil_Type35  \\\n",
       "0                                6279  ...            0            0   \n",
       "1                                6225  ...            0            0   \n",
       "2                                6121  ...            0            0   \n",
       "3                                6211  ...            0            0   \n",
       "4                                6172  ...            0            0   \n",
       "\n",
       "   Soil_Type36  Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Wilderness_Area2  Wilderness_Area3  Wilderness_Area4  \n",
       "0                 0                 0                 0  \n",
       "1                 0                 0                 0  \n",
       "2                 0                 0                 0  \n",
       "3                 0                 0                 0  \n",
       "4                 0                 0                 0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# Load the Covertype dataset\n",
    "\n",
    "covertype_features_filename = \"./data/covertype_features.pkl\"\n",
    "covertype_targets_filename = \"./data/covertype_targets.pkl\"\n",
    "path = Path(covertype_features_filename)\n",
    "\n",
    "if not path.is_file():\n",
    "    # download the dataset. It will take about a minute.\n",
    "    print(\"Downloading dataset\")\n",
    "    covertype = fetch_ucirepo(id=31) \n",
    "    \n",
    "    joblib.dump(covertype.data.features, covertype_features_filename)\n",
    "    joblib.dump(covertype.data.targets, covertype_targets_filename)\n",
    "\n",
    "# Load the covertype dataset\n",
    "covertype_features = joblib.load(covertype_features_filename)\n",
    "covertype_targets = joblib.load(covertype_targets_filename)\n",
    "\n",
    "covertype_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4']\n",
      "Target: ['Cover_Type']\n",
      "Head of data:\n",
      "We have 581012 entries for 54 features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First, let's inspect the data we have to work with\n",
    "print(f\"Features: {list(covertype_features.columns)}\")\n",
    "print(f\"Target: {list(covertype_targets.columns)}\")\n",
    "\n",
    "# Have a variety of pieces of information about the 30x30 meter forest cells\n",
    "print(\"Head of data:\")\n",
    "\n",
    "# And the number of entries\n",
    "print(f\"We have {covertype_features.shape[0]} entries for {covertype_features.shape[1]} features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN Values: 0\n"
     ]
    }
   ],
   "source": [
    "# We also want to clean up our data so it is workable\n",
    "\n",
    "# First, combine into same dataframe\n",
    "df = covertype_features\n",
    "df['Cover_Type'] = covertype_targets\n",
    "\n",
    "# Note that there are no missing datapoints, so nothing needs to be dropped/fixed\n",
    "print(f\"Number of NaN Values: {df.isna().sum().sum()}\")\n",
    "\n",
    "# Also, all of the values are numeric so we don't need to fix that either\n",
    "\n",
    "# Finally, separate into X and y\n",
    "X = df.drop(columns=[\"Cover_Type\"])\n",
    "y = df[\"Cover_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Wilderness_Area2</th>\n",
       "      <th>Wilderness_Area3</th>\n",
       "      <th>Wilderness_Area4</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.297805</td>\n",
       "      <td>-0.935157</td>\n",
       "      <td>-1.482820</td>\n",
       "      <td>-0.053767</td>\n",
       "      <td>-0.796273</td>\n",
       "      <td>-1.180146</td>\n",
       "      <td>0.330743</td>\n",
       "      <td>0.439143</td>\n",
       "      <td>0.142960</td>\n",
       "      <td>3.246283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.319235</td>\n",
       "      <td>-0.890480</td>\n",
       "      <td>-1.616363</td>\n",
       "      <td>-0.270188</td>\n",
       "      <td>-0.899197</td>\n",
       "      <td>-1.257106</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.590899</td>\n",
       "      <td>0.221342</td>\n",
       "      <td>3.205504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.554907</td>\n",
       "      <td>-0.148836</td>\n",
       "      <td>-0.681563</td>\n",
       "      <td>-0.006719</td>\n",
       "      <td>0.318742</td>\n",
       "      <td>0.532212</td>\n",
       "      <td>0.816364</td>\n",
       "      <td>0.742654</td>\n",
       "      <td>-0.196691</td>\n",
       "      <td>3.126965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.622768</td>\n",
       "      <td>-0.005869</td>\n",
       "      <td>0.520322</td>\n",
       "      <td>-0.129044</td>\n",
       "      <td>1.227908</td>\n",
       "      <td>0.474492</td>\n",
       "      <td>0.965786</td>\n",
       "      <td>0.742654</td>\n",
       "      <td>-0.536343</td>\n",
       "      <td>3.194931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.301377</td>\n",
       "      <td>-0.988770</td>\n",
       "      <td>-1.616363</td>\n",
       "      <td>-0.547771</td>\n",
       "      <td>-0.813427</td>\n",
       "      <td>-1.256464</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.540313</td>\n",
       "      <td>0.195215</td>\n",
       "      <td>3.165479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation    Aspect     Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0  -1.297805 -0.935157 -1.482820                         -0.053767   \n",
       "1  -1.319235 -0.890480 -1.616363                         -0.270188   \n",
       "2  -0.554907 -0.148836 -0.681563                         -0.006719   \n",
       "3  -0.622768 -0.005869  0.520322                         -0.129044   \n",
       "4  -1.301377 -0.988770 -1.616363                         -0.547771   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                       -0.796273                        -1.180146   \n",
       "1                       -0.899197                        -1.257106   \n",
       "2                        0.318742                         0.532212   \n",
       "3                        1.227908                         0.474492   \n",
       "4                       -0.813427                        -1.256464   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0       0.330743        0.439143       0.142960   \n",
       "1       0.293388        0.590899       0.221342   \n",
       "2       0.816364        0.742654      -0.196691   \n",
       "3       0.965786        0.742654      -0.536343   \n",
       "4       0.293388        0.540313       0.195215   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type35  Soil_Type36  \\\n",
       "0                            3.246283  ...    -0.057143    -0.014313   \n",
       "1                            3.205504  ...    -0.057143    -0.014313   \n",
       "2                            3.126965  ...    -0.057143    -0.014313   \n",
       "3                            3.194931  ...    -0.057143    -0.014313   \n",
       "4                            3.165479  ...    -0.057143    -0.014313   \n",
       "\n",
       "   Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  Wilderness_Area2  \\\n",
       "0    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "1    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "2    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "3    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "4    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "\n",
       "   Wilderness_Area3  Wilderness_Area4  Cover_Type  \n",
       "0         -0.879364         -0.260673           5  \n",
       "1         -0.879364         -0.260673           5  \n",
       "2         -0.879364         -0.260673           2  \n",
       "3         -0.879364         -0.260673           2  \n",
       "4         -0.879364         -0.260673           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, need to rescale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "df_scaled = pd.DataFrame(data=X_scaled, columns=X.columns)\n",
    "df_scaled[\"Cover_Type\"] = y\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, let's split the data into training and testing sets for ease of work\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cover_Type\n",
       "2    226640\n",
       "1    169472\n",
       "3     28603\n",
       "7     16408\n",
       "6     13894\n",
       "5      7594\n",
       "4      2198\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These next two blocks lets us validate the stratification worked\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cover_Type\n",
       "2    56661\n",
       "1    42368\n",
       "3     7151\n",
       "7     4102\n",
       "6     3473\n",
       "5     1899\n",
       "4      549\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "Our task is to use classify the cover type (type of trees) based on the other features.  First, we will use a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.76879992\n",
      "Iteration 2, loss = 0.65469220\n",
      "Iteration 3, loss = 0.57819546\n",
      "Iteration 4, loss = 0.55308935\n",
      "Iteration 5, loss = 0.53735171\n",
      "Iteration 6, loss = 0.52718581\n",
      "Iteration 7, loss = 0.51830638\n",
      "Iteration 8, loss = 0.51590515\n",
      "Iteration 9, loss = 0.52249009\n",
      "Iteration 10, loss = 0.51257706\n",
      "Iteration 11, loss = 0.51705479\n",
      "Iteration 12, loss = 0.50694554\n",
      "Iteration 13, loss = 0.50701344\n",
      "Iteration 14, loss = 0.50506036\n",
      "Iteration 15, loss = 0.50177372\n",
      "Iteration 16, loss = 0.50630216\n",
      "Iteration 17, loss = 0.49744065\n",
      "Iteration 18, loss = 0.49656242\n",
      "Iteration 19, loss = 0.49648328\n",
      "Iteration 20, loss = 0.49571176\n",
      "Iteration 21, loss = 0.49476679\n",
      "Iteration 22, loss = 0.49684588\n",
      "Iteration 23, loss = 0.49190117\n",
      "Iteration 24, loss = 0.49074462\n",
      "Iteration 25, loss = 0.49276366\n",
      "Iteration 26, loss = 0.48919211\n",
      "Iteration 27, loss = 0.49174111\n",
      "Iteration 28, loss = 0.49227421\n",
      "Iteration 29, loss = 0.48935095\n",
      "Iteration 30, loss = 0.48789111\n",
      "Iteration 31, loss = 0.49336634\n",
      "Iteration 32, loss = 0.49448805\n",
      "Iteration 33, loss = 0.48841614\n",
      "Iteration 34, loss = 0.48785383\n",
      "Iteration 35, loss = 0.49111978\n",
      "Iteration 36, loss = 0.49153012\n",
      "Iteration 37, loss = 0.48646377\n",
      "Iteration 38, loss = 0.50016656\n",
      "Iteration 39, loss = 0.48807433\n",
      "Iteration 40, loss = 0.48683505\n",
      "Iteration 41, loss = 0.48837698\n",
      "Iteration 42, loss = 0.48382386\n",
      "Iteration 43, loss = 0.48575905\n",
      "Iteration 44, loss = 0.48931423\n",
      "Iteration 45, loss = 0.48477552\n",
      "Iteration 46, loss = 0.55795782\n",
      "Iteration 47, loss = 0.50256918\n",
      "Iteration 48, loss = 0.48585900\n",
      "Iteration 49, loss = 0.48883222\n",
      "Iteration 50, loss = 0.48810007\n",
      "Iteration 51, loss = 0.48620669\n",
      "Iteration 52, loss = 0.48521025\n",
      "Iteration 53, loss = 0.49084766\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/mlp.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we'll train a neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural network classifier using scikit-learn's MLPClassifier\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,2),\n",
    "    max_iter=200,\n",
    "    activation=\"relu\",\n",
    "    random_state=42,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-4,\n",
    "    learning_rate_init=0.1,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(mlp,mlp_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 82.12\n",
      "Testing Accuracy: 81.92\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.85      0.83     42368\n",
      "           2       0.85      0.87      0.86     56661\n",
      "           3       0.76      0.82      0.79      7151\n",
      "           4       0.91      0.41      0.57       549\n",
      "           5       0.55      0.01      0.03      1899\n",
      "           6       0.42      0.48      0.45      3473\n",
      "           7       0.97      0.60      0.74      4102\n",
      "\n",
      "    accuracy                           0.82    116203\n",
      "   macro avg       0.75      0.58      0.61    116203\n",
      "weighted avg       0.82      0.82      0.81    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "mlp = joblib.load(mlp_filename)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "y_pred_train = mlp.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = mlp.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5, 6, 7], dtype=int64),\n",
       " array([43817, 57895,  7746,   249,    49,  3928,  2519], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can validate that we are predicting every class\n",
    "# Now we are also predicting tree type 5\n",
    "\n",
    "import numpy as np\n",
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model, `mlp`, got a training accuracy of 82.12% and a testing accuracy of 81.92%.  Took 2m26.7s to train, final loss was 0.49084766 on epoch 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.62477993\n",
      "Iteration 2, loss = 0.55356734\n",
      "Iteration 3, loss = 0.52915173\n",
      "Iteration 4, loss = 0.50934460\n",
      "Iteration 5, loss = 0.51092590\n",
      "Iteration 6, loss = 0.52276864\n",
      "Iteration 7, loss = 0.50501529\n",
      "Iteration 8, loss = 0.49066571\n",
      "Iteration 9, loss = 0.48311636\n",
      "Iteration 10, loss = 0.47907881\n",
      "Iteration 11, loss = 0.46687290\n",
      "Iteration 12, loss = 0.48529709\n",
      "Iteration 13, loss = 0.47400408\n",
      "Iteration 14, loss = 0.47326908\n",
      "Iteration 15, loss = 0.46358356\n",
      "Iteration 16, loss = 0.45931743\n",
      "Iteration 17, loss = 0.45598028\n",
      "Iteration 18, loss = 0.45262431\n",
      "Iteration 19, loss = 0.45131511\n",
      "Iteration 20, loss = 0.44904543\n",
      "Iteration 21, loss = 0.44726675\n",
      "Iteration 22, loss = 0.45346570\n",
      "Iteration 23, loss = 0.44890791\n",
      "Iteration 24, loss = 0.44277065\n",
      "Iteration 25, loss = 0.44296712\n",
      "Iteration 26, loss = 0.44126564\n",
      "Iteration 27, loss = 0.44160908\n",
      "Iteration 28, loss = 0.44195431\n",
      "Iteration 29, loss = 0.43761578\n",
      "Iteration 30, loss = 0.44073169\n",
      "Iteration 31, loss = 0.44069264\n",
      "Iteration 32, loss = 0.44011351\n",
      "Iteration 33, loss = 0.43748542\n",
      "Iteration 34, loss = 0.44398799\n",
      "Iteration 35, loss = 0.43546850\n",
      "Iteration 36, loss = 0.44881635\n",
      "Iteration 37, loss = 0.43918895\n",
      "Iteration 38, loss = 0.43646459\n",
      "Iteration 39, loss = 0.43488083\n",
      "Iteration 40, loss = 0.50902117\n",
      "Iteration 41, loss = 0.49551714\n",
      "Iteration 42, loss = 0.49360763\n",
      "Iteration 43, loss = 0.49503100\n",
      "Iteration 44, loss = 0.49171013\n",
      "Iteration 45, loss = 0.49184882\n",
      "Iteration 46, loss = 0.47115979\n",
      "Iteration 47, loss = 0.44284253\n",
      "Iteration 48, loss = 0.51544526\n",
      "Iteration 49, loss = 0.44307479\n",
      "Iteration 50, loss = 0.44042592\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mlp1_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m mlp1\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Save the model to a file\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(mlp1,\u001b[43mmlp1_filename\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mlp1_filename' is not defined"
     ]
    }
   ],
   "source": [
    "# Now we'll train a second neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural network classifier using scikit-learn's MLPClassifier\n",
    "mlp1 = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,4),\n",
    "    max_iter=200,\n",
    "    activation=\"relu\",\n",
    "    random_state=42,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-4,\n",
    "    learning_rate_init=0.1,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp1.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(mlp1,mlp1_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 80.49\n",
      "Testing Accuracy: 80.27\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.85      0.81     42368\n",
      "           2       0.83      0.86      0.85     56661\n",
      "           3       0.73      0.81      0.77      7151\n",
      "           4       0.70      0.63      0.66       549\n",
      "           5       0.00      0.00      0.00      1899\n",
      "           6       0.59      0.37      0.46      3473\n",
      "           7       0.99      0.30      0.46      4102\n",
      "\n",
      "    accuracy                           0.80    116203\n",
      "   macro avg       0.66      0.55      0.57    116203\n",
      "weighted avg       0.79      0.80      0.79    116203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\C25Dante.Cometto\\487_finalproject\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\C25Dante.Cometto\\487_finalproject\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\C25Dante.Cometto\\487_finalproject\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "mlp1 = joblib.load(mlp1_filename)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "y_pred_train = mlp1.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = mlp1.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model, `mlp1`, had a training accuracy of 80.49%, a testing accuracy of 80.27%, a final loss of 0.44042592 on epoch 50, and took 2m23.4s.  This is worse than `mlp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.58257438\n",
      "Iteration 2, loss = 0.48535005\n",
      "Iteration 3, loss = 0.46439037\n",
      "Iteration 4, loss = 0.44476241\n",
      "Iteration 5, loss = 0.43047432\n",
      "Iteration 6, loss = 0.42255746\n",
      "Iteration 7, loss = 0.41434770\n",
      "Iteration 8, loss = 0.41142993\n",
      "Iteration 9, loss = 0.40641464\n",
      "Iteration 10, loss = 0.40490730\n",
      "Iteration 11, loss = 0.40029871\n",
      "Iteration 12, loss = 0.39815808\n",
      "Iteration 13, loss = 0.39464957\n",
      "Iteration 14, loss = 0.39371239\n",
      "Iteration 15, loss = 0.39447311\n",
      "Iteration 16, loss = 0.38901029\n",
      "Iteration 17, loss = 0.38823212\n",
      "Iteration 18, loss = 0.38936820\n",
      "Iteration 19, loss = 0.38882025\n",
      "Iteration 20, loss = 0.38688025\n",
      "Iteration 21, loss = 0.38522758\n",
      "Iteration 22, loss = 0.38551558\n",
      "Iteration 23, loss = 0.38598591\n",
      "Iteration 24, loss = 0.38493778\n",
      "Iteration 25, loss = 0.39017503\n",
      "Iteration 26, loss = 0.38376372\n",
      "Iteration 27, loss = 0.38418382\n",
      "Iteration 28, loss = 0.38324560\n",
      "Iteration 29, loss = 0.37954608\n",
      "Iteration 30, loss = 0.38141979\n",
      "Iteration 31, loss = 0.38747496\n",
      "Iteration 32, loss = 0.38610786\n",
      "Iteration 33, loss = 0.37946089\n",
      "Iteration 34, loss = 0.37976851\n",
      "Iteration 35, loss = 0.37976220\n",
      "Iteration 36, loss = 0.38248515\n",
      "Iteration 37, loss = 0.38140030\n",
      "Iteration 38, loss = 0.38039142\n",
      "Iteration 39, loss = 0.38265459\n",
      "Iteration 40, loss = 0.37784885\n",
      "Iteration 41, loss = 0.37802281\n",
      "Iteration 42, loss = 0.37859176\n",
      "Iteration 43, loss = 0.38033340\n",
      "Iteration 44, loss = 0.37924378\n",
      "Iteration 45, loss = 0.37792430\n",
      "Iteration 46, loss = 0.37823153\n",
      "Iteration 47, loss = 0.38208480\n",
      "Iteration 48, loss = 0.37961301\n",
      "Iteration 49, loss = 0.37862739\n",
      "Iteration 50, loss = 0.37799876\n",
      "Iteration 51, loss = 0.37705834\n",
      "Iteration 52, loss = 0.37679863\n",
      "Iteration 53, loss = 0.38650128\n",
      "Iteration 54, loss = 0.38007355\n",
      "Iteration 55, loss = 0.37889739\n",
      "Iteration 56, loss = 0.37782095\n",
      "Iteration 57, loss = 0.37713697\n",
      "Iteration 58, loss = 0.37561708\n",
      "Iteration 59, loss = 0.38718104\n",
      "Iteration 60, loss = 0.37897906\n",
      "Iteration 61, loss = 0.38221827\n",
      "Iteration 62, loss = 0.37652907\n",
      "Iteration 63, loss = 0.38113201\n",
      "Iteration 64, loss = 0.37572787\n",
      "Iteration 65, loss = 0.37572843\n",
      "Iteration 66, loss = 0.37680574\n",
      "Iteration 67, loss = 0.37701130\n",
      "Iteration 68, loss = 0.37620736\n",
      "Iteration 69, loss = 0.37746439\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/mlp2.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'll train a third neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural network classifier using scikit-learn's MLPClassifier\n",
    "mlp2 = MLPClassifier(\n",
    "    hidden_layer_sizes=(25,25,25,25),\n",
    "    max_iter=200,\n",
    "    activation=\"relu\",\n",
    "    random_state=42,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-4,\n",
    "    learning_rate_init=0.05,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp2.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(mlp2,mlp2_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 84.99\n",
      "Testing Accuracy: 84.63\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.84      0.85     42368\n",
      "           2       0.86      0.89      0.88     56661\n",
      "           3       0.75      0.87      0.81      7151\n",
      "           4       0.64      0.67      0.66       549\n",
      "           5       0.72      0.44      0.55      1899\n",
      "           6       0.65      0.52      0.58      3473\n",
      "           7       0.92      0.76      0.83      4102\n",
      "\n",
      "    accuracy                           0.85    116203\n",
      "   macro avg       0.77      0.71      0.73    116203\n",
      "weighted avg       0.85      0.85      0.84    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "mlp2 = joblib.load(mlp2_filename)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "y_pred_train = mlp2.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = mlp2.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model, `mlp2`, had a training accuracy of 84.99%, a testing accuracy of 84.63%, a final loss of 0.37746439 on epoch 69, and took 1m40.2s.  Learned how the shape actually works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.53373162\n",
      "Iteration 2, loss = 0.41453588\n",
      "Iteration 3, loss = 0.36622131\n",
      "Iteration 4, loss = 0.33715955\n",
      "Iteration 5, loss = 0.32317365\n",
      "Iteration 6, loss = 0.30514928\n",
      "Iteration 7, loss = 0.29391516\n",
      "Iteration 8, loss = 0.28469076\n",
      "Iteration 9, loss = 0.28099524\n",
      "Iteration 10, loss = 0.27066117\n",
      "Iteration 11, loss = 0.26761203\n",
      "Iteration 12, loss = 0.25922884\n",
      "Iteration 13, loss = 0.25700182\n",
      "Iteration 14, loss = 0.25220525\n",
      "Iteration 15, loss = 0.24845320\n",
      "Iteration 16, loss = 0.24615869\n",
      "Iteration 17, loss = 0.24135625\n",
      "Iteration 18, loss = 0.23831370\n",
      "Iteration 19, loss = 0.23614939\n",
      "Iteration 20, loss = 0.23504337\n",
      "Iteration 21, loss = 0.23199151\n",
      "Iteration 22, loss = 0.23023058\n",
      "Iteration 23, loss = 0.23021492\n",
      "Iteration 24, loss = 0.22814173\n",
      "Iteration 25, loss = 0.23277039\n",
      "Iteration 26, loss = 0.23497191\n",
      "Iteration 27, loss = 0.23043967\n",
      "Iteration 28, loss = 0.22868130\n",
      "Iteration 29, loss = 0.22794161\n",
      "Iteration 30, loss = 0.23231374\n",
      "Iteration 31, loss = 0.22151110\n",
      "Iteration 32, loss = 0.22129987\n",
      "Iteration 33, loss = 0.21856554\n",
      "Iteration 34, loss = 0.21699204\n",
      "Iteration 35, loss = 0.21731308\n",
      "Iteration 36, loss = 0.21355242\n",
      "Iteration 37, loss = 0.21280546\n",
      "Iteration 38, loss = 0.21164773\n",
      "Iteration 39, loss = 0.21178727\n",
      "Iteration 40, loss = 0.20964026\n",
      "Iteration 41, loss = 0.20824563\n",
      "Iteration 42, loss = 0.20762287\n",
      "Iteration 43, loss = 0.20732290\n",
      "Iteration 44, loss = 0.20768938\n",
      "Iteration 45, loss = 0.20669935\n",
      "Iteration 46, loss = 0.20512997\n",
      "Iteration 47, loss = 0.20357742\n",
      "Iteration 48, loss = 0.20609988\n",
      "Iteration 49, loss = 0.20673638\n",
      "Iteration 50, loss = 0.20409029\n",
      "Iteration 51, loss = 0.20211823\n",
      "Iteration 52, loss = 0.20085260\n",
      "Iteration 53, loss = 0.20137443\n",
      "Iteration 54, loss = 0.20248257\n",
      "Iteration 55, loss = 0.20131956\n",
      "Iteration 56, loss = 0.20374607\n",
      "Iteration 57, loss = 0.20054319\n",
      "Iteration 58, loss = 0.20045428\n",
      "Iteration 59, loss = 0.19923297\n",
      "Iteration 60, loss = 0.19894392\n",
      "Iteration 61, loss = 0.20055205\n",
      "Iteration 62, loss = 0.20350952\n",
      "Iteration 63, loss = 0.20286899\n",
      "Iteration 64, loss = 0.20083378\n",
      "Iteration 65, loss = 0.19866325\n",
      "Iteration 66, loss = 0.19941311\n",
      "Iteration 67, loss = 0.19873223\n",
      "Iteration 68, loss = 0.19863003\n",
      "Iteration 69, loss = 0.19879343\n",
      "Iteration 70, loss = 0.19734012\n",
      "Iteration 71, loss = 0.19623332\n",
      "Iteration 72, loss = 0.19817229\n",
      "Iteration 73, loss = 0.20000006\n",
      "Iteration 74, loss = 0.19583004\n",
      "Iteration 75, loss = 0.19613605\n",
      "Iteration 76, loss = 0.22101240\n",
      "Iteration 77, loss = 0.20121158\n",
      "Iteration 78, loss = 0.20927160\n",
      "Iteration 79, loss = 0.20868230\n",
      "Iteration 80, loss = 0.20031723\n",
      "Iteration 81, loss = 0.19761054\n",
      "Iteration 82, loss = 0.19713506\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/mlp3.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'll train a fourth neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural network classifier using scikit-learn's MLPClassifier\n",
    "mlp3 = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,100,25,25,25),\n",
    "    max_iter=200,\n",
    "    activation=\"relu\",\n",
    "    random_state=42,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-3,\n",
    "    learning_rate_init=0.05,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp3.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(mlp3,mlp3_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 92.56\n",
      "Testing Accuracy: 91.86\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.90      0.92     42368\n",
      "           2       0.92      0.95      0.93     56661\n",
      "           3       0.92      0.87      0.90      7151\n",
      "           4       0.79      0.84      0.81       549\n",
      "           5       0.86      0.66      0.74      1899\n",
      "           6       0.79      0.87      0.83      3473\n",
      "           7       0.96      0.86      0.91      4102\n",
      "\n",
      "    accuracy                           0.92    116203\n",
      "   macro avg       0.88      0.85      0.86    116203\n",
      "weighted avg       0.92      0.92      0.92    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "mlp3 = joblib.load(mlp3_filename)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "y_pred_train = mlp3.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = mlp3.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model, `mlp3`, had a training accuracy of 92.56%, a testing accuracy of 91.86%, a final loss of 0.19713506 on epoch 82, and took 9m10.4s.  Weird instability at end led me to decreasing the tolerance so it stopped earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Now, we will use logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\C25Dante.Cometto\\487_finalproject\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 114 seconds\n",
      "Coefficients: [[ 1.92630155e+00 -1.48899529e-01 -4.21799355e-04 -1.00299430e-01\n",
      "  -1.35700739e-01  4.94104814e-02 -1.47012605e-01 -2.25722334e-01\n",
      "   2.13839185e-01  6.09805325e-02  4.46506077e-01 -2.30982816e-01\n",
      "  -4.40210706e-01 -3.29859716e-01 -2.60901917e-01 -1.65919063e-01\n",
      "  -3.45746242e-01 -5.83181832e-02  9.97652902e-03  1.21156134e-01\n",
      "   8.63535917e-03 -1.66101083e-02  1.14646139e-01 -1.66437524e-02\n",
      "  -1.06885410e-01 -6.81375188e-03  1.35901068e-02 -6.13997983e-02\n",
      "   9.55757752e-03  4.37503833e-02  1.42928704e-01  7.61244563e-02\n",
      "   2.67927175e-01  1.77831319e-01  1.41887123e-01  5.44235471e-03\n",
      "   2.15798014e-02  4.16109947e-02  2.37407313e-02 -6.38459935e-02\n",
      "  -7.63908743e-02  1.44280367e-01  5.82312467e-03  1.49282416e-01\n",
      "  -7.56906243e-02 -1.01791839e-02 -2.60848553e-02 -1.19063184e-01\n",
      "  -9.43949664e-02 -4.58781299e-02 -8.94913943e-02  5.68609027e-02\n",
      "  -5.74925898e-02 -8.44500189e-01]\n",
      " [-2.27432003e-01 -1.32790126e-01  1.58389650e-01  2.74346050e-01\n",
      "  -7.55146334e-02  1.79085360e-01 -9.85370692e-02  3.15304097e-01\n",
      "   2.97369560e-02  1.80782804e-02  2.93040438e-01 -3.42648315e-01\n",
      "  -1.31524417e-01  1.07474681e-02 -2.19391750e-01 -2.43976612e-01\n",
      "   6.36285801e-02  2.70430302e-02  8.27256291e-03  5.14644289e-02\n",
      "   2.66446214e-02  3.03447273e-02  2.37945184e-01  6.90943431e-02\n",
      "  -1.82959851e-01 -9.68617036e-03 -2.46940174e-02 -1.10465766e-01\n",
      "   1.98382740e-02 -4.97712341e-03  4.26481708e-02 -6.03155184e-02\n",
      "   4.71742408e-02 -1.63279372e-02  1.16896181e-01  3.68446756e-02\n",
      "   6.58746600e-02  2.93556738e-02  5.97922370e-02 -1.48859732e-02\n",
      "  -3.19657864e-02  1.48287678e-01  1.40871148e-01  1.58775115e-01\n",
      "   3.33966998e-02 -1.84852744e-01  3.35561489e-03 -1.05814684e-01\n",
      "  -2.67501222e-01 -3.08920758e-01 -2.07276078e-01  1.60687391e-01\n",
      "  -2.51320816e-01 -2.31949147e-01]\n",
      " [-1.85143685e+00  1.25288615e-01  2.13783680e-01  4.35080307e-01\n",
      "   7.22338156e-02 -1.97367207e-02 -6.87569676e-02  9.13127687e-02\n",
      "  -8.47359570e-02 -3.72793146e-01 -1.21247306e-01  2.35668862e-01\n",
      "   3.44077462e-01  2.34228251e-01  3.50280946e-01  1.71863361e-01\n",
      "   2.61977692e-01  1.32194004e-02  8.64799062e-03 -4.79753668e-02\n",
      "   3.16401328e-01  2.08123300e-01 -1.33384309e-02 -2.04719960e-01\n",
      "   8.96952103e-02 -2.81969090e-03  5.36885861e-02  6.55480541e-02\n",
      "  -5.28077473e-02 -1.55367112e-03 -9.92744621e-02  3.74102354e-03\n",
      "   3.41993851e-02 -1.00898405e-01 -1.38849174e-01  1.26868875e-02\n",
      "  -4.24231486e-02 -1.09666949e-02 -6.61045604e-02 -1.16577019e-01\n",
      "  -1.82758069e-01 -1.54790816e-01  2.49570797e-02 -3.31154502e-01\n",
      "  -5.12826476e-02  4.15511044e-02  1.99862580e-03  2.62966606e-02\n",
      "   8.60132799e-02  5.41057056e-02  6.49234146e-02  8.37013350e-02\n",
      "   5.25855623e-03  1.60639187e-01]\n",
      " [-5.89985737e-01  7.11858652e-03 -3.99193350e-02 -1.34470019e-01\n",
      "  -1.16396066e-02  2.39337467e-01  2.26498590e-01  1.33056155e-01\n",
      "  -1.43356597e-01 -1.90799317e-02 -3.64517539e-02  1.02313718e-01\n",
      "   3.51347416e-02  2.22828639e-01  2.93002678e-02  4.52452049e-02\n",
      "  -4.50843153e-02  1.15520675e-02  6.68052759e-05 -4.42376608e-03\n",
      "  -3.38424669e-01 -1.26074761e-01  3.70528653e-02 -2.42933081e-02\n",
      "   1.26028780e-01  1.19128354e-03 -1.47262671e-02  1.27385111e-01\n",
      "  -2.15003606e-02 -1.51950271e-03 -2.58501441e-02  2.51211559e-02\n",
      "   9.34430719e-02 -6.53094133e-04  5.20784612e-02  1.01333504e-02\n",
      "   5.04963113e-03  1.43415545e-02  2.69782462e-02 -6.26151888e-02\n",
      "  -1.02027676e-01  4.75909522e-02  4.81297635e-02  3.06077991e-02\n",
      "   1.08517872e-02  3.86262236e-02  6.57880584e-03  2.84441618e-02\n",
      "   5.60188150e-02  7.85312580e-02  5.96572093e-02  6.76620961e-02\n",
      "  -4.89439199e-01  1.00741153e+00]\n",
      " [-7.07540044e-01  1.81269468e-01  1.20572153e-01 -4.47049913e-02\n",
      "   2.22972704e-01 -6.08996598e-01  2.44392079e-01  1.73591012e-01\n",
      "  -1.30231892e-01 -1.92150150e-01  1.83789089e-01 -5.74730600e-02\n",
      "   4.10001289e-02 -2.24842221e-01 -3.63811016e-02 -3.42527332e-02\n",
      "  -1.52251934e-01 -2.26604870e-03 -1.25462267e-02 -9.19994328e-02\n",
      "  -1.76041038e-01  8.04192997e-02 -2.80619197e-01  2.16062783e-01\n",
      "  -5.35748106e-02  1.07998822e-04 -2.60814281e-02  8.38577244e-02\n",
      "   1.20148262e-01  1.23573745e-01 -5.61685379e-02 -4.23759159e-02\n",
      "  -2.77345224e-01  2.10227812e-01 -1.48884226e-01 -2.36477664e-02\n",
      "   1.40831891e-01 -7.10339044e-02  2.14668047e-02  1.90817328e-01\n",
      "   3.88877143e-01  8.27609868e-02  1.43100391e-03 -1.56199734e-02\n",
      "   4.95268167e-03 -4.26628824e-02 -1.67542542e-02 -1.95203283e-03\n",
      "  -1.46019853e-01 -1.53520958e-01 -1.06083422e-01 -2.58131775e-01\n",
      "   1.46055015e-01 -4.37647852e-01]\n",
      " [-1.59009336e+00  3.29526547e-02 -3.63414445e-01 -7.71130601e-02\n",
      "  -2.86605032e-02  8.38130817e-02 -1.83979156e-01 -3.89402141e-01\n",
      "   2.22898268e-01  3.22987947e-02 -3.98947153e-01  2.47173423e-01\n",
      "   1.98393174e-01  9.15065941e-02  3.96398663e-02  1.92748394e-01\n",
      "   1.86843361e-01  7.40554945e-03 -2.62773168e-03 -4.33970526e-02\n",
      "   2.99299410e-01 -1.26203715e-03 -5.82744103e-02  2.14957977e-01\n",
      "   1.15380984e-01  1.58966406e-02  6.85389979e-02  3.39301699e-02\n",
      "  -7.44817166e-02 -6.18378836e-02  1.21586038e-01 -2.85593036e-02\n",
      "  -6.73152235e-02 -2.50491671e-01  2.11130488e-02  9.79615653e-03\n",
      "  -8.32199234e-02 -8.52359286e-03 -5.95128158e-02 -1.83754821e-01\n",
      "  -1.42468267e-01 -1.37028097e-01 -1.43859174e-02  9.72614219e-02\n",
      "   4.93522913e-02  1.75307083e-02  3.31803673e-03  1.87974873e-02\n",
      "   3.05091957e-02  7.23585598e-03  4.15634091e-02  1.32698633e-02\n",
      "   2.89950610e-01  2.11855022e-01]\n",
      " [ 3.04018645e+00 -6.49396694e-02 -8.89899033e-02 -3.52838856e-01\n",
      "  -4.36910379e-02  7.70869292e-02  2.73951295e-02 -9.81395593e-02\n",
      "  -1.08149963e-01  4.72665620e-01 -3.66689391e-01  4.59481871e-02\n",
      "  -4.68703832e-02 -4.60901499e-03  9.74536887e-02  3.42914479e-02\n",
      "   3.06328579e-02  1.36418446e-03 -1.17899295e-02  1.51750553e-02\n",
      "  -1.36515012e-01 -1.74940421e-01 -3.74121495e-02 -2.54458083e-01\n",
      "   1.23150980e-02  2.12369015e-03 -7.03159782e-02 -1.38855495e-01\n",
      "  -7.54289432e-04 -9.74359474e-02 -1.25869769e-01  2.62641022e-02\n",
      "  -9.80834257e-02 -1.96880235e-02 -4.42414139e-02 -5.12556583e-02\n",
      "  -1.07692912e-01  5.21596920e-03 -6.36064301e-03  2.50861668e-01\n",
      "   1.46733529e-01 -1.31101071e-01 -2.06826202e-01 -8.91522760e-02\n",
      "   2.84198119e-02  1.39986774e-01  2.75880262e-02  1.53291591e-01\n",
      "   3.35374751e-01  3.68447026e-01  2.36706861e-01 -1.24049813e-01\n",
      "   3.56988424e-01  1.34191453e-01]]\n",
      "Intercept: [ 2.9809831   4.0259326  -1.7009424  -2.03002628 -0.66249382 -1.44861774\n",
      " -1.16483547]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\C25Dante.Cometto\\487_finalproject\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/lreg.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "import joblib\n",
    "\n",
    "# Create a logistic regression model\n",
    "lreg = LogisticRegression(penalty='None', \n",
    "                          dual=False, \n",
    "                          tol=0.0001, \n",
    "                          C=1.0, \n",
    "                          fit_intercept=True, \n",
    "                          intercept_scaling=1, \n",
    "                          class_weight=None,\n",
    "                          random_state=42, \n",
    "                          solver='saga', \n",
    "                          max_iter=100, \n",
    "                          multi_class='multinomial', \n",
    "                          verbose=1, \n",
    "                          warm_start=False, \n",
    "                          n_jobs=None, \n",
    "                          l1_ratio=None)\n",
    "\n",
    "# Train the model on the training data\n",
    "lreg.fit(X_train, y_train)\n",
    "\n",
    "# Print the model's coefficients and intercept\n",
    "print(\"Coefficients:\", lreg.coef_)\n",
    "print(\"Intercept:\", lreg.intercept_)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(lreg,lreg_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[29332 12151    28     0     0     4   853]\n",
      " [10036 45203  1055     2    46   222    97]\n",
      " [    0   633  6023   137     7   351     0]\n",
      " [    0     0   323   144     0    82     0]\n",
      " [    8  1810    69     0    10     2     0]\n",
      " [    0   964  1856    25    21   607     0]\n",
      " [ 1873    36     4     0     0     0  2189]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.69      0.70     42368\n",
      "           2       0.74      0.80      0.77     56661\n",
      "           3       0.64      0.84      0.73      7151\n",
      "           4       0.47      0.26      0.34       549\n",
      "           5       0.12      0.01      0.01      1899\n",
      "           6       0.48      0.17      0.26      3473\n",
      "           7       0.70      0.53      0.60      4102\n",
      "\n",
      "    accuracy                           0.72    116203\n",
      "   macro avg       0.55      0.47      0.49    116203\n",
      "weighted avg       0.70      0.72      0.71    116203\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[29332 12151    28     0     0     4   853]\n",
      " [10036 45203  1055     2    46   222    97]\n",
      " [    0   633  6023   137     7   351     0]\n",
      " [    0     0   323   144     0    82     0]\n",
      " [    8  1810    69     0    10     2     0]\n",
      " [    0   964  1856    25    21   607     0]\n",
      " [ 1873    36     4     0     0     0  2189]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.69      0.70     42368\n",
      "           2       0.74      0.80      0.77     56661\n",
      "           3       0.64      0.84      0.73      7151\n",
      "           4       0.47      0.26      0.34       549\n",
      "           5       0.12      0.01      0.01      1899\n",
      "           6       0.48      0.17      0.26      3473\n",
      "           7       0.70      0.53      0.60      4102\n",
      "\n",
      "    accuracy                           0.72    116203\n",
      "   macro avg       0.55      0.47      0.49    116203\n",
      "weighted avg       0.70      0.72      0.71    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now check results\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "y_pred = lreg.predict(X_test)\n",
    "\n",
    "# confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "\n",
    "# For a ROC... multiclass is more complicated\n",
    "# Several methods, choosing Micro-Averaged for best overall summary\n",
    "probs = lreg.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# Binarize the true labels\n",
    "classes = np.unique(y_test)\n",
    "y_true_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# Compute micro-average ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_true_binarized.ravel(), probs.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the micro-averaged ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"Micro-Averaged ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Diagonal line\n",
    "for i, threshold in enumerate(thresholds[::len(thresholds)//5]):\n",
    "    plt.annotate(f'Threshold={threshold:.2f}', \n",
    "                 xy=(fpr[i], tpr[i]), \n",
    "                 xytext=(fpr[i] + 0.05, tpr[i] - 0.05),\n",
    "                 arrowprops=dict(facecolor='black', arrowstyle=\"->\"),\n",
    "                 fontsize=10)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Micro-Averaged ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Then, can choose a different threshold\n",
    "threshold = 0.7\n",
    "y_pred2 = (probs >= threshold).astype(int)\n",
    "\n",
    "# confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
