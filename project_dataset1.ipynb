{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the file for Dataset 1, \"Covertype.\"  We will be classifying the type of trees in the forest based on the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful Variables\n",
    "mlp_filename = \"./models/mlp.pkl\"\n",
    "mlp1_filename = \"./models/mlp1.pkl\"\n",
    "mlp2_filename = \"./models/mlp2.pkl\"\n",
    "mlp3_filename = \"./models/mlp3.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Wilderness_Area2</th>\n",
       "      <th>Wilderness_Area3</th>\n",
       "      <th>Wilderness_Area4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type34  Soil_Type35  \\\n",
       "0                                6279  ...            0            0   \n",
       "1                                6225  ...            0            0   \n",
       "2                                6121  ...            0            0   \n",
       "3                                6211  ...            0            0   \n",
       "4                                6172  ...            0            0   \n",
       "\n",
       "   Soil_Type36  Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Wilderness_Area2  Wilderness_Area3  Wilderness_Area4  \n",
       "0                 0                 0                 0  \n",
       "1                 0                 0                 0  \n",
       "2                 0                 0                 0  \n",
       "3                 0                 0                 0  \n",
       "4                 0                 0                 0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# Load the Covertype dataset\n",
    "\n",
    "covertype_features_filename = \"./data/covertype_features.pkl\"\n",
    "covertype_targets_filename = \"./data/covertype_targets.pkl\"\n",
    "path = Path(covertype_features_filename)\n",
    "\n",
    "if not path.is_file():\n",
    "    # download the dataset. It will take about a minute.\n",
    "    print(\"Downloading dataset\")\n",
    "    covertype = fetch_ucirepo(id=31) \n",
    "    \n",
    "    joblib.dump(covertype.data.features, covertype_features_filename)\n",
    "    joblib.dump(covertype.data.targets, covertype_targets_filename)\n",
    "\n",
    "# Load the covertype dataset\n",
    "covertype_features = joblib.load(covertype_features_filename)\n",
    "covertype_targets = joblib.load(covertype_targets_filename)\n",
    "\n",
    "covertype_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4']\n",
      "Target: ['Cover_Type']\n",
      "Head of data:\n",
      "We have 581012 entries for 54 features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First, let's inspect the data we have to work with\n",
    "print(f\"Features: {list(covertype_features.columns)}\")\n",
    "print(f\"Target: {list(covertype_targets.columns)}\")\n",
    "\n",
    "# Have a variety of pieces of information about the 30x30 meter forest cells\n",
    "print(\"Head of data:\")\n",
    "\n",
    "# And the number of entries\n",
    "print(f\"We have {covertype_features.shape[0]} entries for {covertype_features.shape[1]} features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN Values: 0\n"
     ]
    }
   ],
   "source": [
    "# We also want to clean up our data so it is workable\n",
    "\n",
    "# First, combine into same dataframe\n",
    "df = covertype_features\n",
    "df['Cover_Type'] = covertype_targets\n",
    "\n",
    "# Note that there are no missing datapoints, so nothing needs to be dropped/fixed\n",
    "print(f\"Number of NaN Values: {df.isna().sum().sum()}\")\n",
    "\n",
    "# Also, all of the values are numeric so we don't need to fix that either\n",
    "\n",
    "# Finally, separate into X and y\n",
    "X = df.drop(columns=[\"Cover_Type\"])\n",
    "y = df[\"Cover_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Wilderness_Area2</th>\n",
       "      <th>Wilderness_Area3</th>\n",
       "      <th>Wilderness_Area4</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.297805</td>\n",
       "      <td>-0.935157</td>\n",
       "      <td>-1.482820</td>\n",
       "      <td>-0.053767</td>\n",
       "      <td>-0.796273</td>\n",
       "      <td>-1.180146</td>\n",
       "      <td>0.330743</td>\n",
       "      <td>0.439143</td>\n",
       "      <td>0.142960</td>\n",
       "      <td>3.246283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.319235</td>\n",
       "      <td>-0.890480</td>\n",
       "      <td>-1.616363</td>\n",
       "      <td>-0.270188</td>\n",
       "      <td>-0.899197</td>\n",
       "      <td>-1.257106</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.590899</td>\n",
       "      <td>0.221342</td>\n",
       "      <td>3.205504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.554907</td>\n",
       "      <td>-0.148836</td>\n",
       "      <td>-0.681563</td>\n",
       "      <td>-0.006719</td>\n",
       "      <td>0.318742</td>\n",
       "      <td>0.532212</td>\n",
       "      <td>0.816364</td>\n",
       "      <td>0.742654</td>\n",
       "      <td>-0.196691</td>\n",
       "      <td>3.126965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.622768</td>\n",
       "      <td>-0.005869</td>\n",
       "      <td>0.520322</td>\n",
       "      <td>-0.129044</td>\n",
       "      <td>1.227908</td>\n",
       "      <td>0.474492</td>\n",
       "      <td>0.965786</td>\n",
       "      <td>0.742654</td>\n",
       "      <td>-0.536343</td>\n",
       "      <td>3.194931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.301377</td>\n",
       "      <td>-0.988770</td>\n",
       "      <td>-1.616363</td>\n",
       "      <td>-0.547771</td>\n",
       "      <td>-0.813427</td>\n",
       "      <td>-1.256464</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.540313</td>\n",
       "      <td>0.195215</td>\n",
       "      <td>3.165479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation    Aspect     Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0  -1.297805 -0.935157 -1.482820                         -0.053767   \n",
       "1  -1.319235 -0.890480 -1.616363                         -0.270188   \n",
       "2  -0.554907 -0.148836 -0.681563                         -0.006719   \n",
       "3  -0.622768 -0.005869  0.520322                         -0.129044   \n",
       "4  -1.301377 -0.988770 -1.616363                         -0.547771   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                       -0.796273                        -1.180146   \n",
       "1                       -0.899197                        -1.257106   \n",
       "2                        0.318742                         0.532212   \n",
       "3                        1.227908                         0.474492   \n",
       "4                       -0.813427                        -1.256464   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0       0.330743        0.439143       0.142960   \n",
       "1       0.293388        0.590899       0.221342   \n",
       "2       0.816364        0.742654      -0.196691   \n",
       "3       0.965786        0.742654      -0.536343   \n",
       "4       0.293388        0.540313       0.195215   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type35  Soil_Type36  \\\n",
       "0                            3.246283  ...    -0.057143    -0.014313   \n",
       "1                            3.205504  ...    -0.057143    -0.014313   \n",
       "2                            3.126965  ...    -0.057143    -0.014313   \n",
       "3                            3.194931  ...    -0.057143    -0.014313   \n",
       "4                            3.165479  ...    -0.057143    -0.014313   \n",
       "\n",
       "   Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  Wilderness_Area2  \\\n",
       "0    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "1    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "2    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "3    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "4    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "\n",
       "   Wilderness_Area3  Wilderness_Area4  Cover_Type  \n",
       "0         -0.879364         -0.260673           5  \n",
       "1         -0.879364         -0.260673           5  \n",
       "2         -0.879364         -0.260673           2  \n",
       "3         -0.879364         -0.260673           2  \n",
       "4         -0.879364         -0.260673           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, need to rescale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "df_scaled = pd.DataFrame(data=X_scaled, columns=X.columns)\n",
    "df_scaled[\"Cover_Type\"] = y\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, let's split the data into training and testing sets for ease of work\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cover_Type\n",
       "2    226640\n",
       "1    169472\n",
       "3     28603\n",
       "7     16408\n",
       "6     13894\n",
       "5      7594\n",
       "4      2198\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These next two blocks lets us validate the stratification worked\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cover_Type\n",
       "2    56661\n",
       "1    42368\n",
       "3     7151\n",
       "7     4102\n",
       "6     3473\n",
       "5     1899\n",
       "4      549\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "Our task is to use classify the cover type (type of trees) based on the other features.  First, we will use a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.76879992\n",
      "Iteration 2, loss = 0.65469220\n",
      "Iteration 3, loss = 0.57819546\n",
      "Iteration 4, loss = 0.55308935\n",
      "Iteration 5, loss = 0.53735171\n",
      "Iteration 6, loss = 0.52718581\n",
      "Iteration 7, loss = 0.51830638\n",
      "Iteration 8, loss = 0.51590515\n",
      "Iteration 9, loss = 0.52249009\n",
      "Iteration 10, loss = 0.51257706\n",
      "Iteration 11, loss = 0.51705479\n",
      "Iteration 12, loss = 0.50694554\n",
      "Iteration 13, loss = 0.50701344\n",
      "Iteration 14, loss = 0.50506036\n",
      "Iteration 15, loss = 0.50177372\n",
      "Iteration 16, loss = 0.50630216\n",
      "Iteration 17, loss = 0.49744065\n",
      "Iteration 18, loss = 0.49656242\n",
      "Iteration 19, loss = 0.49648328\n",
      "Iteration 20, loss = 0.49571176\n",
      "Iteration 21, loss = 0.49476679\n",
      "Iteration 22, loss = 0.49684588\n",
      "Iteration 23, loss = 0.49190117\n",
      "Iteration 24, loss = 0.49074462\n",
      "Iteration 25, loss = 0.49276366\n",
      "Iteration 26, loss = 0.48919211\n",
      "Iteration 27, loss = 0.49174111\n",
      "Iteration 28, loss = 0.49227421\n",
      "Iteration 29, loss = 0.48935095\n",
      "Iteration 30, loss = 0.48789111\n",
      "Iteration 31, loss = 0.49336634\n",
      "Iteration 32, loss = 0.49448805\n",
      "Iteration 33, loss = 0.48841614\n",
      "Iteration 34, loss = 0.48785383\n",
      "Iteration 35, loss = 0.49111978\n",
      "Iteration 36, loss = 0.49153012\n",
      "Iteration 37, loss = 0.48646377\n",
      "Iteration 38, loss = 0.50016656\n",
      "Iteration 39, loss = 0.48807433\n",
      "Iteration 40, loss = 0.48683505\n",
      "Iteration 41, loss = 0.48837698\n",
      "Iteration 42, loss = 0.48382386\n",
      "Iteration 43, loss = 0.48575905\n",
      "Iteration 44, loss = 0.48931423\n",
      "Iteration 45, loss = 0.48477552\n",
      "Iteration 46, loss = 0.55795782\n",
      "Iteration 47, loss = 0.50256918\n",
      "Iteration 48, loss = 0.48585900\n",
      "Iteration 49, loss = 0.48883222\n",
      "Iteration 50, loss = 0.48810007\n",
      "Iteration 51, loss = 0.48620669\n",
      "Iteration 52, loss = 0.48521025\n",
      "Iteration 53, loss = 0.49084766\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/mlp.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we'll train a neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural network classifier using scikit-learn's MLPClassifier\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,2),\n",
    "    max_iter=200,\n",
    "    activation=\"relu\",\n",
    "    random_state=42,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-4,\n",
    "    learning_rate_init=0.1,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(mlp,mlp_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 82.12\n",
      "Testing Accuracy: 81.92\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.85      0.83     42368\n",
      "           2       0.85      0.87      0.86     56661\n",
      "           3       0.76      0.82      0.79      7151\n",
      "           4       0.91      0.41      0.57       549\n",
      "           5       0.55      0.01      0.03      1899\n",
      "           6       0.42      0.48      0.45      3473\n",
      "           7       0.97      0.60      0.74      4102\n",
      "\n",
      "    accuracy                           0.82    116203\n",
      "   macro avg       0.75      0.58      0.61    116203\n",
      "weighted avg       0.82      0.82      0.81    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "mlp = joblib.load(mlp_filename)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "y_pred_train = mlp.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = mlp.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5, 6, 7], dtype=int64),\n",
       " array([43817, 57895,  7746,   249,    49,  3928,  2519], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can validate that we are predicting every class\n",
    "# Now we are also predicting tree type 5\n",
    "\n",
    "import numpy as np\n",
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model, `mlp`, got a training accuracy of 82.12% and a testing accuracy of 81.92%.  Took 2m26.7s to train, final loss was 0.49084766 on epoch 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.62477993\n",
      "Iteration 2, loss = 0.55356734\n",
      "Iteration 3, loss = 0.52915173\n",
      "Iteration 4, loss = 0.50934460\n",
      "Iteration 5, loss = 0.51092590\n",
      "Iteration 6, loss = 0.52276864\n",
      "Iteration 7, loss = 0.50501529\n",
      "Iteration 8, loss = 0.49066571\n",
      "Iteration 9, loss = 0.48311636\n",
      "Iteration 10, loss = 0.47907881\n",
      "Iteration 11, loss = 0.46687290\n",
      "Iteration 12, loss = 0.48529709\n",
      "Iteration 13, loss = 0.47400408\n",
      "Iteration 14, loss = 0.47326908\n",
      "Iteration 15, loss = 0.46358356\n",
      "Iteration 16, loss = 0.45931743\n",
      "Iteration 17, loss = 0.45598028\n",
      "Iteration 18, loss = 0.45262431\n",
      "Iteration 19, loss = 0.45131511\n",
      "Iteration 20, loss = 0.44904543\n",
      "Iteration 21, loss = 0.44726675\n",
      "Iteration 22, loss = 0.45346570\n",
      "Iteration 23, loss = 0.44890791\n",
      "Iteration 24, loss = 0.44277065\n",
      "Iteration 25, loss = 0.44296712\n",
      "Iteration 26, loss = 0.44126564\n",
      "Iteration 27, loss = 0.44160908\n",
      "Iteration 28, loss = 0.44195431\n",
      "Iteration 29, loss = 0.43761578\n",
      "Iteration 30, loss = 0.44073169\n",
      "Iteration 31, loss = 0.44069264\n",
      "Iteration 32, loss = 0.44011351\n",
      "Iteration 33, loss = 0.43748542\n",
      "Iteration 34, loss = 0.44398799\n",
      "Iteration 35, loss = 0.43546850\n",
      "Iteration 36, loss = 0.44881635\n",
      "Iteration 37, loss = 0.43918895\n",
      "Iteration 38, loss = 0.43646459\n",
      "Iteration 39, loss = 0.43488083\n",
      "Iteration 40, loss = 0.50902117\n",
      "Iteration 41, loss = 0.49551714\n",
      "Iteration 42, loss = 0.49360763\n",
      "Iteration 43, loss = 0.49503100\n",
      "Iteration 44, loss = 0.49171013\n",
      "Iteration 45, loss = 0.49184882\n",
      "Iteration 46, loss = 0.47115979\n",
      "Iteration 47, loss = 0.44284253\n",
      "Iteration 48, loss = 0.51544526\n",
      "Iteration 49, loss = 0.44307479\n",
      "Iteration 50, loss = 0.44042592\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mlp1_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m mlp1\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Save the model to a file\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(mlp1,\u001b[43mmlp1_filename\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mlp1_filename' is not defined"
     ]
    }
   ],
   "source": [
    "# Now we'll train a second neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural network classifier using scikit-learn's MLPClassifier\n",
    "mlp1 = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,4),\n",
    "    max_iter=200,\n",
    "    activation=\"relu\",\n",
    "    random_state=42,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-4,\n",
    "    learning_rate_init=0.1,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp1.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(mlp1,mlp1_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 80.49\n",
      "Testing Accuracy: 80.27\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.85      0.81     42368\n",
      "           2       0.83      0.86      0.85     56661\n",
      "           3       0.73      0.81      0.77      7151\n",
      "           4       0.70      0.63      0.66       549\n",
      "           5       0.00      0.00      0.00      1899\n",
      "           6       0.59      0.37      0.46      3473\n",
      "           7       0.99      0.30      0.46      4102\n",
      "\n",
      "    accuracy                           0.80    116203\n",
      "   macro avg       0.66      0.55      0.57    116203\n",
      "weighted avg       0.79      0.80      0.79    116203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\C25Dante.Cometto\\487_finalproject\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\C25Dante.Cometto\\487_finalproject\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\C25Dante.Cometto\\487_finalproject\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "mlp1 = joblib.load(mlp1_filename)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "y_pred_train = mlp1.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = mlp1.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model, `mlp1`, had a training accuracy of 80.49%, a testing accuracy of 80.27%, a final loss of 0.44042592 on epoch 50, and took 2m23.4s.  This is worse than `mlp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.58257438\n",
      "Iteration 2, loss = 0.48535005\n",
      "Iteration 3, loss = 0.46439037\n",
      "Iteration 4, loss = 0.44476241\n",
      "Iteration 5, loss = 0.43047432\n",
      "Iteration 6, loss = 0.42255746\n",
      "Iteration 7, loss = 0.41434770\n",
      "Iteration 8, loss = 0.41142993\n",
      "Iteration 9, loss = 0.40641464\n",
      "Iteration 10, loss = 0.40490730\n",
      "Iteration 11, loss = 0.40029871\n",
      "Iteration 12, loss = 0.39815808\n",
      "Iteration 13, loss = 0.39464957\n",
      "Iteration 14, loss = 0.39371239\n",
      "Iteration 15, loss = 0.39447311\n",
      "Iteration 16, loss = 0.38901029\n",
      "Iteration 17, loss = 0.38823212\n",
      "Iteration 18, loss = 0.38936820\n",
      "Iteration 19, loss = 0.38882025\n",
      "Iteration 20, loss = 0.38688025\n",
      "Iteration 21, loss = 0.38522758\n",
      "Iteration 22, loss = 0.38551558\n",
      "Iteration 23, loss = 0.38598591\n",
      "Iteration 24, loss = 0.38493778\n",
      "Iteration 25, loss = 0.39017503\n",
      "Iteration 26, loss = 0.38376372\n",
      "Iteration 27, loss = 0.38418382\n",
      "Iteration 28, loss = 0.38324560\n",
      "Iteration 29, loss = 0.37954608\n",
      "Iteration 30, loss = 0.38141979\n",
      "Iteration 31, loss = 0.38747496\n",
      "Iteration 32, loss = 0.38610786\n",
      "Iteration 33, loss = 0.37946089\n",
      "Iteration 34, loss = 0.37976851\n",
      "Iteration 35, loss = 0.37976220\n",
      "Iteration 36, loss = 0.38248515\n",
      "Iteration 37, loss = 0.38140030\n",
      "Iteration 38, loss = 0.38039142\n",
      "Iteration 39, loss = 0.38265459\n",
      "Iteration 40, loss = 0.37784885\n",
      "Iteration 41, loss = 0.37802281\n",
      "Iteration 42, loss = 0.37859176\n",
      "Iteration 43, loss = 0.38033340\n",
      "Iteration 44, loss = 0.37924378\n",
      "Iteration 45, loss = 0.37792430\n",
      "Iteration 46, loss = 0.37823153\n",
      "Iteration 47, loss = 0.38208480\n",
      "Iteration 48, loss = 0.37961301\n",
      "Iteration 49, loss = 0.37862739\n",
      "Iteration 50, loss = 0.37799876\n",
      "Iteration 51, loss = 0.37705834\n",
      "Iteration 52, loss = 0.37679863\n",
      "Iteration 53, loss = 0.38650128\n",
      "Iteration 54, loss = 0.38007355\n",
      "Iteration 55, loss = 0.37889739\n",
      "Iteration 56, loss = 0.37782095\n",
      "Iteration 57, loss = 0.37713697\n",
      "Iteration 58, loss = 0.37561708\n",
      "Iteration 59, loss = 0.38718104\n",
      "Iteration 60, loss = 0.37897906\n",
      "Iteration 61, loss = 0.38221827\n",
      "Iteration 62, loss = 0.37652907\n",
      "Iteration 63, loss = 0.38113201\n",
      "Iteration 64, loss = 0.37572787\n",
      "Iteration 65, loss = 0.37572843\n",
      "Iteration 66, loss = 0.37680574\n",
      "Iteration 67, loss = 0.37701130\n",
      "Iteration 68, loss = 0.37620736\n",
      "Iteration 69, loss = 0.37746439\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/mlp2.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'll train a third neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural network classifier using scikit-learn's MLPClassifier\n",
    "mlp2 = MLPClassifier(\n",
    "    hidden_layer_sizes=(25,25,25,25),\n",
    "    max_iter=200,\n",
    "    activation=\"relu\",\n",
    "    random_state=42,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-4,\n",
    "    learning_rate_init=0.05,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp2.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(mlp2,mlp2_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 84.99\n",
      "Testing Accuracy: 84.63\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.84      0.85     42368\n",
      "           2       0.86      0.89      0.88     56661\n",
      "           3       0.75      0.87      0.81      7151\n",
      "           4       0.64      0.67      0.66       549\n",
      "           5       0.72      0.44      0.55      1899\n",
      "           6       0.65      0.52      0.58      3473\n",
      "           7       0.92      0.76      0.83      4102\n",
      "\n",
      "    accuracy                           0.85    116203\n",
      "   macro avg       0.77      0.71      0.73    116203\n",
      "weighted avg       0.85      0.85      0.84    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "mlp2 = joblib.load(mlp2_filename)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "y_pred_train = mlp2.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = mlp2.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model, `mlp2`, had a training accuracy of 84.99%, a testing accuracy of 84.63%, a final loss of 0.37746439 on epoch 69, and took 1m40.2s.  Learned how the shape actually works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.53373162\n",
      "Iteration 2, loss = 0.41453588\n",
      "Iteration 3, loss = 0.36622131\n",
      "Iteration 4, loss = 0.33715955\n",
      "Iteration 5, loss = 0.32317365\n",
      "Iteration 6, loss = 0.30514928\n",
      "Iteration 7, loss = 0.29391516\n",
      "Iteration 8, loss = 0.28469076\n",
      "Iteration 9, loss = 0.28099524\n",
      "Iteration 10, loss = 0.27066117\n",
      "Iteration 11, loss = 0.26761203\n",
      "Iteration 12, loss = 0.25922884\n",
      "Iteration 13, loss = 0.25700182\n",
      "Iteration 14, loss = 0.25220525\n",
      "Iteration 15, loss = 0.24845320\n",
      "Iteration 16, loss = 0.24615869\n",
      "Iteration 17, loss = 0.24135625\n",
      "Iteration 18, loss = 0.23831370\n",
      "Iteration 19, loss = 0.23614939\n",
      "Iteration 20, loss = 0.23504337\n",
      "Iteration 21, loss = 0.23199151\n",
      "Iteration 22, loss = 0.23023058\n",
      "Iteration 23, loss = 0.23021492\n",
      "Iteration 24, loss = 0.22814173\n",
      "Iteration 25, loss = 0.23277039\n",
      "Iteration 26, loss = 0.23497191\n",
      "Iteration 27, loss = 0.23043967\n",
      "Iteration 28, loss = 0.22868130\n",
      "Iteration 29, loss = 0.22794161\n",
      "Iteration 30, loss = 0.23231374\n",
      "Iteration 31, loss = 0.22151110\n",
      "Iteration 32, loss = 0.22129987\n",
      "Iteration 33, loss = 0.21856554\n",
      "Iteration 34, loss = 0.21699204\n",
      "Iteration 35, loss = 0.21731308\n",
      "Iteration 36, loss = 0.21355242\n",
      "Iteration 37, loss = 0.21280546\n",
      "Iteration 38, loss = 0.21164773\n",
      "Iteration 39, loss = 0.21178727\n",
      "Iteration 40, loss = 0.20964026\n",
      "Iteration 41, loss = 0.20824563\n",
      "Iteration 42, loss = 0.20762287\n",
      "Iteration 43, loss = 0.20732290\n",
      "Iteration 44, loss = 0.20768938\n",
      "Iteration 45, loss = 0.20669935\n",
      "Iteration 46, loss = 0.20512997\n",
      "Iteration 47, loss = 0.20357742\n",
      "Iteration 48, loss = 0.20609988\n",
      "Iteration 49, loss = 0.20673638\n",
      "Iteration 50, loss = 0.20409029\n",
      "Iteration 51, loss = 0.20211823\n",
      "Iteration 52, loss = 0.20085260\n",
      "Iteration 53, loss = 0.20137443\n",
      "Iteration 54, loss = 0.20248257\n",
      "Iteration 55, loss = 0.20131956\n",
      "Iteration 56, loss = 0.20374607\n",
      "Iteration 57, loss = 0.20054319\n",
      "Iteration 58, loss = 0.20045428\n",
      "Iteration 59, loss = 0.19923297\n",
      "Iteration 60, loss = 0.19894392\n",
      "Iteration 61, loss = 0.20055205\n",
      "Iteration 62, loss = 0.20350952\n",
      "Iteration 63, loss = 0.20286899\n",
      "Iteration 64, loss = 0.20083378\n",
      "Iteration 65, loss = 0.19866325\n",
      "Iteration 66, loss = 0.19941311\n",
      "Iteration 67, loss = 0.19873223\n",
      "Iteration 68, loss = 0.19863003\n",
      "Iteration 69, loss = 0.19879343\n",
      "Iteration 70, loss = 0.19734012\n",
      "Iteration 71, loss = 0.19623332\n",
      "Iteration 72, loss = 0.19817229\n",
      "Iteration 73, loss = 0.20000006\n",
      "Iteration 74, loss = 0.19583004\n",
      "Iteration 75, loss = 0.19613605\n",
      "Iteration 76, loss = 0.22101240\n",
      "Iteration 77, loss = 0.20121158\n",
      "Iteration 78, loss = 0.20927160\n",
      "Iteration 79, loss = 0.20868230\n",
      "Iteration 80, loss = 0.20031723\n",
      "Iteration 81, loss = 0.19761054\n",
      "Iteration 82, loss = 0.19713506\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/mlp3.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'll train a fourth neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural network classifier using scikit-learn's MLPClassifier\n",
    "mlp3 = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,100,25,25,25),\n",
    "    max_iter=200,\n",
    "    activation=\"relu\",\n",
    "    random_state=42,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-3,\n",
    "    learning_rate_init=0.05,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp3.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(mlp3,mlp3_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 92.56\n",
      "Testing Accuracy: 91.86\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.90      0.92     42368\n",
      "           2       0.92      0.95      0.93     56661\n",
      "           3       0.92      0.87      0.90      7151\n",
      "           4       0.79      0.84      0.81       549\n",
      "           5       0.86      0.66      0.74      1899\n",
      "           6       0.79      0.87      0.83      3473\n",
      "           7       0.96      0.86      0.91      4102\n",
      "\n",
      "    accuracy                           0.92    116203\n",
      "   macro avg       0.88      0.85      0.86    116203\n",
      "weighted avg       0.92      0.92      0.92    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "mlp3 = joblib.load(mlp3_filename)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "y_pred_train = mlp3.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = mlp3.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model, `mlp3`, had a training accuracy of 92.56%, a testing accuracy of 91.86%, a final loss of 0.19713506 on epoch 82, and took 9m10.4s.  Weird instability at end led me to decreasing the tolerance so it stopped earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add logistic regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
