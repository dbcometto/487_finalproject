{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the file for Dataset 2, \"Covertype.\"  We will be classifying the type of trees in the forest based on the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful Variables\n",
    "mlp_filename = \"./models/mlp.pkl\"\n",
    "mlp1_filename = \"./models/mlp1.pkl\"\n",
    "mlp2_filename = \"./models/mlp2.pkl\"\n",
    "mlp3_filename = \"./models/mlp3.pkl\"\n",
    "\n",
    "lreg_filename = \"./models/lreg.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Wilderness_Area2</th>\n",
       "      <th>Wilderness_Area3</th>\n",
       "      <th>Wilderness_Area4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type34  Soil_Type35  \\\n",
       "0                                6279  ...            0            0   \n",
       "1                                6225  ...            0            0   \n",
       "2                                6121  ...            0            0   \n",
       "3                                6211  ...            0            0   \n",
       "4                                6172  ...            0            0   \n",
       "\n",
       "   Soil_Type36  Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Wilderness_Area2  Wilderness_Area3  Wilderness_Area4  \n",
       "0                 0                 0                 0  \n",
       "1                 0                 0                 0  \n",
       "2                 0                 0                 0  \n",
       "3                 0                 0                 0  \n",
       "4                 0                 0                 0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# Load the Covertype dataset\n",
    "\n",
    "covertype_features_filename = \"./data/covertype_features.pkl\"\n",
    "covertype_targets_filename = \"./data/covertype_targets.pkl\"\n",
    "path = Path(covertype_features_filename)\n",
    "\n",
    "if not path.is_file():\n",
    "    # download the dataset. It will take about a minute.\n",
    "    print(\"Downloading dataset\")\n",
    "    covertype = fetch_ucirepo(id=31) \n",
    "    \n",
    "    joblib.dump(covertype.data.features, covertype_features_filename)\n",
    "    joblib.dump(covertype.data.targets, covertype_targets_filename)\n",
    "\n",
    "# Load the covertype dataset\n",
    "covertype_features = joblib.load(covertype_features_filename)\n",
    "covertype_targets = joblib.load(covertype_targets_filename)\n",
    "\n",
    "covertype_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4']\n",
      "Target: ['Cover_Type']\n",
      "Head of data:\n",
      "We have 581012 entries for 54 features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First, let's inspect the data we have to work with\n",
    "print(f\"Features: {list(covertype_features.columns)}\")\n",
    "print(f\"Target: {list(covertype_targets.columns)}\")\n",
    "\n",
    "# Have a variety of pieces of information about the 30x30 meter forest cells\n",
    "print(\"Head of data:\")\n",
    "\n",
    "# And the number of entries\n",
    "print(f\"We have {covertype_features.shape[0]} entries for {covertype_features.shape[1]} features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN Values: 0\n"
     ]
    }
   ],
   "source": [
    "# We also want to clean up our data so it is workable\n",
    "\n",
    "# First, combine into same dataframe\n",
    "df = covertype_features\n",
    "df['Cover_Type'] = covertype_targets\n",
    "\n",
    "# Note that there are no missing datapoints, so nothing needs to be dropped/fixed\n",
    "print(f\"Number of NaN Values: {df.isna().sum().sum()}\")\n",
    "\n",
    "# Also, all of the values are numeric so we don't need to fix that either\n",
    "\n",
    "# Finally, separate into X and y\n",
    "X = df.drop(columns=[\"Cover_Type\"])\n",
    "y = df[\"Cover_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Wilderness_Area2</th>\n",
       "      <th>Wilderness_Area3</th>\n",
       "      <th>Wilderness_Area4</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.297805</td>\n",
       "      <td>-0.935157</td>\n",
       "      <td>-1.482820</td>\n",
       "      <td>-0.053767</td>\n",
       "      <td>-0.796273</td>\n",
       "      <td>-1.180146</td>\n",
       "      <td>0.330743</td>\n",
       "      <td>0.439143</td>\n",
       "      <td>0.142960</td>\n",
       "      <td>3.246283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.319235</td>\n",
       "      <td>-0.890480</td>\n",
       "      <td>-1.616363</td>\n",
       "      <td>-0.270188</td>\n",
       "      <td>-0.899197</td>\n",
       "      <td>-1.257106</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.590899</td>\n",
       "      <td>0.221342</td>\n",
       "      <td>3.205504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.554907</td>\n",
       "      <td>-0.148836</td>\n",
       "      <td>-0.681563</td>\n",
       "      <td>-0.006719</td>\n",
       "      <td>0.318742</td>\n",
       "      <td>0.532212</td>\n",
       "      <td>0.816364</td>\n",
       "      <td>0.742654</td>\n",
       "      <td>-0.196691</td>\n",
       "      <td>3.126965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.622768</td>\n",
       "      <td>-0.005869</td>\n",
       "      <td>0.520322</td>\n",
       "      <td>-0.129044</td>\n",
       "      <td>1.227908</td>\n",
       "      <td>0.474492</td>\n",
       "      <td>0.965786</td>\n",
       "      <td>0.742654</td>\n",
       "      <td>-0.536343</td>\n",
       "      <td>3.194931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.301377</td>\n",
       "      <td>-0.988770</td>\n",
       "      <td>-1.616363</td>\n",
       "      <td>-0.547771</td>\n",
       "      <td>-0.813427</td>\n",
       "      <td>-1.256464</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.540313</td>\n",
       "      <td>0.195215</td>\n",
       "      <td>3.165479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>-0.014313</td>\n",
       "      <td>-0.022653</td>\n",
       "      <td>-0.165956</td>\n",
       "      <td>-0.156014</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.232859</td>\n",
       "      <td>-0.879364</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation    Aspect     Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0  -1.297805 -0.935157 -1.482820                         -0.053767   \n",
       "1  -1.319235 -0.890480 -1.616363                         -0.270188   \n",
       "2  -0.554907 -0.148836 -0.681563                         -0.006719   \n",
       "3  -0.622768 -0.005869  0.520322                         -0.129044   \n",
       "4  -1.301377 -0.988770 -1.616363                         -0.547771   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                       -0.796273                        -1.180146   \n",
       "1                       -0.899197                        -1.257106   \n",
       "2                        0.318742                         0.532212   \n",
       "3                        1.227908                         0.474492   \n",
       "4                       -0.813427                        -1.256464   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0       0.330743        0.439143       0.142960   \n",
       "1       0.293388        0.590899       0.221342   \n",
       "2       0.816364        0.742654      -0.196691   \n",
       "3       0.965786        0.742654      -0.536343   \n",
       "4       0.293388        0.540313       0.195215   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type35  Soil_Type36  \\\n",
       "0                            3.246283  ...    -0.057143    -0.014313   \n",
       "1                            3.205504  ...    -0.057143    -0.014313   \n",
       "2                            3.126965  ...    -0.057143    -0.014313   \n",
       "3                            3.194931  ...    -0.057143    -0.014313   \n",
       "4                            3.165479  ...    -0.057143    -0.014313   \n",
       "\n",
       "   Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  Wilderness_Area2  \\\n",
       "0    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "1    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "2    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "3    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "4    -0.022653    -0.165956    -0.156014    -0.123654         -0.232859   \n",
       "\n",
       "   Wilderness_Area3  Wilderness_Area4  Cover_Type  \n",
       "0         -0.879364         -0.260673           5  \n",
       "1         -0.879364         -0.260673           5  \n",
       "2         -0.879364         -0.260673           2  \n",
       "3         -0.879364         -0.260673           2  \n",
       "4         -0.879364         -0.260673           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, need to rescale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "df_scaled = pd.DataFrame(data=X_scaled, columns=X.columns)\n",
    "df_scaled[\"Cover_Type\"] = y\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, let's split the data into training and testing sets for ease of work\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cover_Type\n",
       "2    226640\n",
       "1    169472\n",
       "3     28603\n",
       "7     16408\n",
       "6     13894\n",
       "5      7594\n",
       "4      2198\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These next two blocks lets us validate the stratification worked\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cover_Type\n",
       "2    56661\n",
       "1    42368\n",
       "3     7151\n",
       "7     4102\n",
       "6     3473\n",
       "5     1899\n",
       "4      549\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "Our task is to use classify the cover type (type of trees) based on the other features.  First, we will use a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.76879992\n",
      "Iteration 2, loss = 0.65469220\n",
      "Iteration 3, loss = 0.57819546\n",
      "Iteration 4, loss = 0.55308935\n",
      "Iteration 5, loss = 0.53735171\n",
      "Iteration 6, loss = 0.52718581\n",
      "Iteration 7, loss = 0.51830638\n",
      "Iteration 8, loss = 0.51590515\n",
      "Iteration 9, loss = 0.52249009\n",
      "Iteration 10, loss = 0.51257706\n",
      "Iteration 11, loss = 0.51705479\n",
      "Iteration 12, loss = 0.50694554\n",
      "Iteration 13, loss = 0.50701344\n",
      "Iteration 14, loss = 0.50506036\n",
      "Iteration 15, loss = 0.50177372\n",
      "Iteration 16, loss = 0.50630216\n",
      "Iteration 17, loss = 0.49744065\n",
      "Iteration 18, loss = 0.49656242\n",
      "Iteration 19, loss = 0.49648328\n",
      "Iteration 20, loss = 0.49571176\n",
      "Iteration 21, loss = 0.49476679\n",
      "Iteration 22, loss = 0.49684588\n",
      "Iteration 23, loss = 0.49190117\n",
      "Iteration 24, loss = 0.49074462\n",
      "Iteration 25, loss = 0.49276366\n",
      "Iteration 26, loss = 0.48919211\n",
      "Iteration 27, loss = 0.49174111\n",
      "Iteration 28, loss = 0.49227421\n",
      "Iteration 29, loss = 0.48935095\n",
      "Iteration 30, loss = 0.48789111\n",
      "Iteration 31, loss = 0.49336634\n",
      "Iteration 32, loss = 0.49448805\n",
      "Iteration 33, loss = 0.48841614\n",
      "Iteration 34, loss = 0.48785383\n",
      "Iteration 35, loss = 0.49111978\n",
      "Iteration 36, loss = 0.49153012\n",
      "Iteration 37, loss = 0.48646377\n",
      "Iteration 38, loss = 0.50016656\n",
      "Iteration 39, loss = 0.48807433\n",
      "Iteration 40, loss = 0.48683505\n",
      "Iteration 41, loss = 0.48837698\n",
      "Iteration 42, loss = 0.48382386\n",
      "Iteration 43, loss = 0.48575905\n",
      "Iteration 44, loss = 0.48931423\n",
      "Iteration 45, loss = 0.48477552\n",
      "Iteration 46, loss = 0.55795782\n",
      "Iteration 47, loss = 0.50256918\n",
      "Iteration 48, loss = 0.48585900\n",
      "Iteration 49, loss = 0.48883222\n",
      "Iteration 50, loss = 0.48810007\n",
      "Iteration 51, loss = 0.48620669\n",
      "Iteration 52, loss = 0.48521025\n",
      "Iteration 53, loss = 0.49084766\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/mlp.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we'll train a neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural network classifier using scikit-learn's MLPClassifier\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,2),\n",
    "    max_iter=200,\n",
    "    activation=\"relu\",\n",
    "    random_state=42,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-4,\n",
    "    learning_rate_init=0.1,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(mlp,mlp_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 82.12\n",
      "Testing Accuracy: 81.92\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.85      0.83     42368\n",
      "           2       0.85      0.87      0.86     56661\n",
      "           3       0.76      0.82      0.79      7151\n",
      "           4       0.91      0.41      0.57       549\n",
      "           5       0.55      0.01      0.03      1899\n",
      "           6       0.42      0.48      0.45      3473\n",
      "           7       0.97      0.60      0.74      4102\n",
      "\n",
      "    accuracy                           0.82    116203\n",
      "   macro avg       0.75      0.58      0.61    116203\n",
      "weighted avg       0.82      0.82      0.81    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "mlp = joblib.load(mlp_filename)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "y_pred_train = mlp.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = mlp.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5, 6, 7], dtype=int64),\n",
       " array([43817, 57895,  7746,   249,    49,  3928,  2519], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can validate that we are predicting every class\n",
    "# Now we are also predicting tree type 5\n",
    "\n",
    "import numpy as np\n",
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model, `mlp`, got a training accuracy of 82.12% and a testing accuracy of 81.92%.  Took 2m26.7s to train, final loss was 0.49084766 on epoch 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.62477993\n",
      "Iteration 2, loss = 0.55356734\n",
      "Iteration 3, loss = 0.52915173\n",
      "Iteration 4, loss = 0.50934460\n",
      "Iteration 5, loss = 0.51092590\n",
      "Iteration 6, loss = 0.52276864\n",
      "Iteration 7, loss = 0.50501529\n",
      "Iteration 8, loss = 0.49066571\n",
      "Iteration 9, loss = 0.48311636\n",
      "Iteration 10, loss = 0.47907881\n",
      "Iteration 11, loss = 0.46687290\n",
      "Iteration 12, loss = 0.48529709\n",
      "Iteration 13, loss = 0.47400408\n",
      "Iteration 14, loss = 0.47326908\n",
      "Iteration 15, loss = 0.46358356\n",
      "Iteration 16, loss = 0.45931743\n",
      "Iteration 17, loss = 0.45598028\n",
      "Iteration 18, loss = 0.45262431\n",
      "Iteration 19, loss = 0.45131511\n",
      "Iteration 20, loss = 0.44904543\n",
      "Iteration 21, loss = 0.44726675\n",
      "Iteration 22, loss = 0.45346570\n",
      "Iteration 23, loss = 0.44890791\n",
      "Iteration 24, loss = 0.44277065\n",
      "Iteration 25, loss = 0.44296712\n",
      "Iteration 26, loss = 0.44126564\n",
      "Iteration 27, loss = 0.44160908\n",
      "Iteration 28, loss = 0.44195431\n",
      "Iteration 29, loss = 0.43761578\n",
      "Iteration 30, loss = 0.44073169\n",
      "Iteration 31, loss = 0.44069264\n",
      "Iteration 32, loss = 0.44011351\n",
      "Iteration 33, loss = 0.43748542\n",
      "Iteration 34, loss = 0.44398799\n",
      "Iteration 35, loss = 0.43546850\n",
      "Iteration 36, loss = 0.44881635\n",
      "Iteration 37, loss = 0.43918895\n",
      "Iteration 38, loss = 0.43646459\n",
      "Iteration 39, loss = 0.43488083\n",
      "Iteration 40, loss = 0.50902117\n",
      "Iteration 41, loss = 0.49551714\n",
      "Iteration 42, loss = 0.49360763\n",
      "Iteration 43, loss = 0.49503100\n",
      "Iteration 44, loss = 0.49171013\n",
      "Iteration 45, loss = 0.49184882\n",
      "Iteration 46, loss = 0.47115979\n",
      "Iteration 47, loss = 0.44284253\n",
      "Iteration 48, loss = 0.51544526\n",
      "Iteration 49, loss = 0.44307479\n",
      "Iteration 50, loss = 0.44042592\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mlp1_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m mlp1\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Save the model to a file\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(mlp1,\u001b[43mmlp1_filename\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mlp1_filename' is not defined"
     ]
    }
   ],
   "source": [
    "# Now we'll train a second neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural network classifier using scikit-learn's MLPClassifier\n",
    "mlp1 = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,4),\n",
    "    max_iter=200,\n",
    "    activation=\"relu\",\n",
    "    random_state=42,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-4,\n",
    "    learning_rate_init=0.1,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp1.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(mlp1,mlp1_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 80.49\n",
      "Testing Accuracy: 80.27\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.85      0.81     42368\n",
      "           2       0.83      0.86      0.85     56661\n",
      "           3       0.73      0.81      0.77      7151\n",
      "           4       0.70      0.63      0.66       549\n",
      "           5       0.00      0.00      0.00      1899\n",
      "           6       0.59      0.37      0.46      3473\n",
      "           7       0.99      0.30      0.46      4102\n",
      "\n",
      "    accuracy                           0.80    116203\n",
      "   macro avg       0.66      0.55      0.57    116203\n",
      "weighted avg       0.79      0.80      0.79    116203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\C25Dante.Cometto\\487_finalproject\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\C25Dante.Cometto\\487_finalproject\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\C25Dante.Cometto\\487_finalproject\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "mlp1 = joblib.load(mlp1_filename)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "y_pred_train = mlp1.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = mlp1.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model, `mlp1`, had a training accuracy of 80.49%, a testing accuracy of 80.27%, a final loss of 0.44042592 on epoch 50, and took 2m23.4s.  This is worse than `mlp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.58257438\n",
      "Iteration 2, loss = 0.48535005\n",
      "Iteration 3, loss = 0.46439037\n",
      "Iteration 4, loss = 0.44476241\n",
      "Iteration 5, loss = 0.43047432\n",
      "Iteration 6, loss = 0.42255746\n",
      "Iteration 7, loss = 0.41434770\n",
      "Iteration 8, loss = 0.41142993\n",
      "Iteration 9, loss = 0.40641464\n",
      "Iteration 10, loss = 0.40490730\n",
      "Iteration 11, loss = 0.40029871\n",
      "Iteration 12, loss = 0.39815808\n",
      "Iteration 13, loss = 0.39464957\n",
      "Iteration 14, loss = 0.39371239\n",
      "Iteration 15, loss = 0.39447311\n",
      "Iteration 16, loss = 0.38901029\n",
      "Iteration 17, loss = 0.38823212\n",
      "Iteration 18, loss = 0.38936820\n",
      "Iteration 19, loss = 0.38882025\n",
      "Iteration 20, loss = 0.38688025\n",
      "Iteration 21, loss = 0.38522758\n",
      "Iteration 22, loss = 0.38551558\n",
      "Iteration 23, loss = 0.38598591\n",
      "Iteration 24, loss = 0.38493778\n",
      "Iteration 25, loss = 0.39017503\n",
      "Iteration 26, loss = 0.38376372\n",
      "Iteration 27, loss = 0.38418382\n",
      "Iteration 28, loss = 0.38324560\n",
      "Iteration 29, loss = 0.37954608\n",
      "Iteration 30, loss = 0.38141979\n",
      "Iteration 31, loss = 0.38747496\n",
      "Iteration 32, loss = 0.38610786\n",
      "Iteration 33, loss = 0.37946089\n",
      "Iteration 34, loss = 0.37976851\n",
      "Iteration 35, loss = 0.37976220\n",
      "Iteration 36, loss = 0.38248515\n",
      "Iteration 37, loss = 0.38140030\n",
      "Iteration 38, loss = 0.38039142\n",
      "Iteration 39, loss = 0.38265459\n",
      "Iteration 40, loss = 0.37784885\n",
      "Iteration 41, loss = 0.37802281\n",
      "Iteration 42, loss = 0.37859176\n",
      "Iteration 43, loss = 0.38033340\n",
      "Iteration 44, loss = 0.37924378\n",
      "Iteration 45, loss = 0.37792430\n",
      "Iteration 46, loss = 0.37823153\n",
      "Iteration 47, loss = 0.38208480\n",
      "Iteration 48, loss = 0.37961301\n",
      "Iteration 49, loss = 0.37862739\n",
      "Iteration 50, loss = 0.37799876\n",
      "Iteration 51, loss = 0.37705834\n",
      "Iteration 52, loss = 0.37679863\n",
      "Iteration 53, loss = 0.38650128\n",
      "Iteration 54, loss = 0.38007355\n",
      "Iteration 55, loss = 0.37889739\n",
      "Iteration 56, loss = 0.37782095\n",
      "Iteration 57, loss = 0.37713697\n",
      "Iteration 58, loss = 0.37561708\n",
      "Iteration 59, loss = 0.38718104\n",
      "Iteration 60, loss = 0.37897906\n",
      "Iteration 61, loss = 0.38221827\n",
      "Iteration 62, loss = 0.37652907\n",
      "Iteration 63, loss = 0.38113201\n",
      "Iteration 64, loss = 0.37572787\n",
      "Iteration 65, loss = 0.37572843\n",
      "Iteration 66, loss = 0.37680574\n",
      "Iteration 67, loss = 0.37701130\n",
      "Iteration 68, loss = 0.37620736\n",
      "Iteration 69, loss = 0.37746439\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/mlp2.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'll train a third neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural network classifier using scikit-learn's MLPClassifier\n",
    "mlp2 = MLPClassifier(\n",
    "    hidden_layer_sizes=(25,25,25,25),\n",
    "    max_iter=200,\n",
    "    activation=\"relu\",\n",
    "    random_state=42,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-4,\n",
    "    learning_rate_init=0.05,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp2.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(mlp2,mlp2_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 84.99\n",
      "Testing Accuracy: 84.63\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.84      0.85     42368\n",
      "           2       0.86      0.89      0.88     56661\n",
      "           3       0.75      0.87      0.81      7151\n",
      "           4       0.64      0.67      0.66       549\n",
      "           5       0.72      0.44      0.55      1899\n",
      "           6       0.65      0.52      0.58      3473\n",
      "           7       0.92      0.76      0.83      4102\n",
      "\n",
      "    accuracy                           0.85    116203\n",
      "   macro avg       0.77      0.71      0.73    116203\n",
      "weighted avg       0.85      0.85      0.84    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "mlp2 = joblib.load(mlp2_filename)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "y_pred_train = mlp2.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = mlp2.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model, `mlp2`, had a training accuracy of 84.99%, a testing accuracy of 84.63%, a final loss of 0.37746439 on epoch 69, and took 1m40.2s.  Learned how the shape actually works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.53373162\n",
      "Iteration 2, loss = 0.41453588\n",
      "Iteration 3, loss = 0.36622131\n",
      "Iteration 4, loss = 0.33715955\n",
      "Iteration 5, loss = 0.32317365\n",
      "Iteration 6, loss = 0.30514928\n",
      "Iteration 7, loss = 0.29391516\n",
      "Iteration 8, loss = 0.28469076\n",
      "Iteration 9, loss = 0.28099524\n",
      "Iteration 10, loss = 0.27066117\n",
      "Iteration 11, loss = 0.26761203\n",
      "Iteration 12, loss = 0.25922884\n",
      "Iteration 13, loss = 0.25700182\n",
      "Iteration 14, loss = 0.25220525\n",
      "Iteration 15, loss = 0.24845320\n",
      "Iteration 16, loss = 0.24615869\n",
      "Iteration 17, loss = 0.24135625\n",
      "Iteration 18, loss = 0.23831370\n",
      "Iteration 19, loss = 0.23614939\n",
      "Iteration 20, loss = 0.23504337\n",
      "Iteration 21, loss = 0.23199151\n",
      "Iteration 22, loss = 0.23023058\n",
      "Iteration 23, loss = 0.23021492\n",
      "Iteration 24, loss = 0.22814173\n",
      "Iteration 25, loss = 0.23277039\n",
      "Iteration 26, loss = 0.23497191\n",
      "Iteration 27, loss = 0.23043967\n",
      "Iteration 28, loss = 0.22868130\n",
      "Iteration 29, loss = 0.22794161\n",
      "Iteration 30, loss = 0.23231374\n",
      "Iteration 31, loss = 0.22151110\n",
      "Iteration 32, loss = 0.22129987\n",
      "Iteration 33, loss = 0.21856554\n",
      "Iteration 34, loss = 0.21699204\n",
      "Iteration 35, loss = 0.21731308\n",
      "Iteration 36, loss = 0.21355242\n",
      "Iteration 37, loss = 0.21280546\n",
      "Iteration 38, loss = 0.21164773\n",
      "Iteration 39, loss = 0.21178727\n",
      "Iteration 40, loss = 0.20964026\n",
      "Iteration 41, loss = 0.20824563\n",
      "Iteration 42, loss = 0.20762287\n",
      "Iteration 43, loss = 0.20732290\n",
      "Iteration 44, loss = 0.20768938\n",
      "Iteration 45, loss = 0.20669935\n",
      "Iteration 46, loss = 0.20512997\n",
      "Iteration 47, loss = 0.20357742\n",
      "Iteration 48, loss = 0.20609988\n",
      "Iteration 49, loss = 0.20673638\n",
      "Iteration 50, loss = 0.20409029\n",
      "Iteration 51, loss = 0.20211823\n",
      "Iteration 52, loss = 0.20085260\n",
      "Iteration 53, loss = 0.20137443\n",
      "Iteration 54, loss = 0.20248257\n",
      "Iteration 55, loss = 0.20131956\n",
      "Iteration 56, loss = 0.20374607\n",
      "Iteration 57, loss = 0.20054319\n",
      "Iteration 58, loss = 0.20045428\n",
      "Iteration 59, loss = 0.19923297\n",
      "Iteration 60, loss = 0.19894392\n",
      "Iteration 61, loss = 0.20055205\n",
      "Iteration 62, loss = 0.20350952\n",
      "Iteration 63, loss = 0.20286899\n",
      "Iteration 64, loss = 0.20083378\n",
      "Iteration 65, loss = 0.19866325\n",
      "Iteration 66, loss = 0.19941311\n",
      "Iteration 67, loss = 0.19873223\n",
      "Iteration 68, loss = 0.19863003\n",
      "Iteration 69, loss = 0.19879343\n",
      "Iteration 70, loss = 0.19734012\n",
      "Iteration 71, loss = 0.19623332\n",
      "Iteration 72, loss = 0.19817229\n",
      "Iteration 73, loss = 0.20000006\n",
      "Iteration 74, loss = 0.19583004\n",
      "Iteration 75, loss = 0.19613605\n",
      "Iteration 76, loss = 0.22101240\n",
      "Iteration 77, loss = 0.20121158\n",
      "Iteration 78, loss = 0.20927160\n",
      "Iteration 79, loss = 0.20868230\n",
      "Iteration 80, loss = 0.20031723\n",
      "Iteration 81, loss = 0.19761054\n",
      "Iteration 82, loss = 0.19713506\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/mlp3.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'll train a fourth neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a neural network classifier using scikit-learn's MLPClassifier\n",
    "mlp3 = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,100,25,25,25),\n",
    "    max_iter=200,\n",
    "    activation=\"relu\",\n",
    "    random_state=42,\n",
    "    solver=\"sgd\",\n",
    "    verbose=1,\n",
    "    tol=1e-3,\n",
    "    learning_rate_init=0.05,\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp3.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(mlp3,mlp3_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 92.56\n",
      "Testing Accuracy: 91.86\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.90      0.92     42368\n",
      "           2       0.92      0.95      0.93     56661\n",
      "           3       0.92      0.87      0.90      7151\n",
      "           4       0.79      0.84      0.81       549\n",
      "           5       0.86      0.66      0.74      1899\n",
      "           6       0.79      0.87      0.83      3473\n",
      "           7       0.96      0.86      0.91      4102\n",
      "\n",
      "    accuracy                           0.92    116203\n",
      "   macro avg       0.88      0.85      0.86    116203\n",
      "weighted avg       0.92      0.92      0.92    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "mlp3 = joblib.load(mlp3_filename)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "y_pred_train = mlp3.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = mlp3.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {accuracy * 100:.2f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model, `mlp3`, had a training accuracy of 92.56%, a testing accuracy of 91.86%, a final loss of 0.19713506 on epoch 82, and took 9m10.4s.  Weird instability at end led me to decreasing the tolerance so it stopped earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Now, we will use logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\C25Dante.Cometto\\487_finalproject\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 114 seconds\n",
      "Coefficients: [[ 1.92630155e+00 -1.48899529e-01 -4.21799355e-04 -1.00299430e-01\n",
      "  -1.35700739e-01  4.94104814e-02 -1.47012605e-01 -2.25722334e-01\n",
      "   2.13839185e-01  6.09805325e-02  4.46506077e-01 -2.30982816e-01\n",
      "  -4.40210706e-01 -3.29859716e-01 -2.60901917e-01 -1.65919063e-01\n",
      "  -3.45746242e-01 -5.83181832e-02  9.97652902e-03  1.21156134e-01\n",
      "   8.63535917e-03 -1.66101083e-02  1.14646139e-01 -1.66437524e-02\n",
      "  -1.06885410e-01 -6.81375188e-03  1.35901068e-02 -6.13997983e-02\n",
      "   9.55757752e-03  4.37503833e-02  1.42928704e-01  7.61244563e-02\n",
      "   2.67927175e-01  1.77831319e-01  1.41887123e-01  5.44235471e-03\n",
      "   2.15798014e-02  4.16109947e-02  2.37407313e-02 -6.38459935e-02\n",
      "  -7.63908743e-02  1.44280367e-01  5.82312467e-03  1.49282416e-01\n",
      "  -7.56906243e-02 -1.01791839e-02 -2.60848553e-02 -1.19063184e-01\n",
      "  -9.43949664e-02 -4.58781299e-02 -8.94913943e-02  5.68609027e-02\n",
      "  -5.74925898e-02 -8.44500189e-01]\n",
      " [-2.27432003e-01 -1.32790126e-01  1.58389650e-01  2.74346050e-01\n",
      "  -7.55146334e-02  1.79085360e-01 -9.85370692e-02  3.15304097e-01\n",
      "   2.97369560e-02  1.80782804e-02  2.93040438e-01 -3.42648315e-01\n",
      "  -1.31524417e-01  1.07474681e-02 -2.19391750e-01 -2.43976612e-01\n",
      "   6.36285801e-02  2.70430302e-02  8.27256291e-03  5.14644289e-02\n",
      "   2.66446214e-02  3.03447273e-02  2.37945184e-01  6.90943431e-02\n",
      "  -1.82959851e-01 -9.68617036e-03 -2.46940174e-02 -1.10465766e-01\n",
      "   1.98382740e-02 -4.97712341e-03  4.26481708e-02 -6.03155184e-02\n",
      "   4.71742408e-02 -1.63279372e-02  1.16896181e-01  3.68446756e-02\n",
      "   6.58746600e-02  2.93556738e-02  5.97922370e-02 -1.48859732e-02\n",
      "  -3.19657864e-02  1.48287678e-01  1.40871148e-01  1.58775115e-01\n",
      "   3.33966998e-02 -1.84852744e-01  3.35561489e-03 -1.05814684e-01\n",
      "  -2.67501222e-01 -3.08920758e-01 -2.07276078e-01  1.60687391e-01\n",
      "  -2.51320816e-01 -2.31949147e-01]\n",
      " [-1.85143685e+00  1.25288615e-01  2.13783680e-01  4.35080307e-01\n",
      "   7.22338156e-02 -1.97367207e-02 -6.87569676e-02  9.13127687e-02\n",
      "  -8.47359570e-02 -3.72793146e-01 -1.21247306e-01  2.35668862e-01\n",
      "   3.44077462e-01  2.34228251e-01  3.50280946e-01  1.71863361e-01\n",
      "   2.61977692e-01  1.32194004e-02  8.64799062e-03 -4.79753668e-02\n",
      "   3.16401328e-01  2.08123300e-01 -1.33384309e-02 -2.04719960e-01\n",
      "   8.96952103e-02 -2.81969090e-03  5.36885861e-02  6.55480541e-02\n",
      "  -5.28077473e-02 -1.55367112e-03 -9.92744621e-02  3.74102354e-03\n",
      "   3.41993851e-02 -1.00898405e-01 -1.38849174e-01  1.26868875e-02\n",
      "  -4.24231486e-02 -1.09666949e-02 -6.61045604e-02 -1.16577019e-01\n",
      "  -1.82758069e-01 -1.54790816e-01  2.49570797e-02 -3.31154502e-01\n",
      "  -5.12826476e-02  4.15511044e-02  1.99862580e-03  2.62966606e-02\n",
      "   8.60132799e-02  5.41057056e-02  6.49234146e-02  8.37013350e-02\n",
      "   5.25855623e-03  1.60639187e-01]\n",
      " [-5.89985737e-01  7.11858652e-03 -3.99193350e-02 -1.34470019e-01\n",
      "  -1.16396066e-02  2.39337467e-01  2.26498590e-01  1.33056155e-01\n",
      "  -1.43356597e-01 -1.90799317e-02 -3.64517539e-02  1.02313718e-01\n",
      "   3.51347416e-02  2.22828639e-01  2.93002678e-02  4.52452049e-02\n",
      "  -4.50843153e-02  1.15520675e-02  6.68052759e-05 -4.42376608e-03\n",
      "  -3.38424669e-01 -1.26074761e-01  3.70528653e-02 -2.42933081e-02\n",
      "   1.26028780e-01  1.19128354e-03 -1.47262671e-02  1.27385111e-01\n",
      "  -2.15003606e-02 -1.51950271e-03 -2.58501441e-02  2.51211559e-02\n",
      "   9.34430719e-02 -6.53094133e-04  5.20784612e-02  1.01333504e-02\n",
      "   5.04963113e-03  1.43415545e-02  2.69782462e-02 -6.26151888e-02\n",
      "  -1.02027676e-01  4.75909522e-02  4.81297635e-02  3.06077991e-02\n",
      "   1.08517872e-02  3.86262236e-02  6.57880584e-03  2.84441618e-02\n",
      "   5.60188150e-02  7.85312580e-02  5.96572093e-02  6.76620961e-02\n",
      "  -4.89439199e-01  1.00741153e+00]\n",
      " [-7.07540044e-01  1.81269468e-01  1.20572153e-01 -4.47049913e-02\n",
      "   2.22972704e-01 -6.08996598e-01  2.44392079e-01  1.73591012e-01\n",
      "  -1.30231892e-01 -1.92150150e-01  1.83789089e-01 -5.74730600e-02\n",
      "   4.10001289e-02 -2.24842221e-01 -3.63811016e-02 -3.42527332e-02\n",
      "  -1.52251934e-01 -2.26604870e-03 -1.25462267e-02 -9.19994328e-02\n",
      "  -1.76041038e-01  8.04192997e-02 -2.80619197e-01  2.16062783e-01\n",
      "  -5.35748106e-02  1.07998822e-04 -2.60814281e-02  8.38577244e-02\n",
      "   1.20148262e-01  1.23573745e-01 -5.61685379e-02 -4.23759159e-02\n",
      "  -2.77345224e-01  2.10227812e-01 -1.48884226e-01 -2.36477664e-02\n",
      "   1.40831891e-01 -7.10339044e-02  2.14668047e-02  1.90817328e-01\n",
      "   3.88877143e-01  8.27609868e-02  1.43100391e-03 -1.56199734e-02\n",
      "   4.95268167e-03 -4.26628824e-02 -1.67542542e-02 -1.95203283e-03\n",
      "  -1.46019853e-01 -1.53520958e-01 -1.06083422e-01 -2.58131775e-01\n",
      "   1.46055015e-01 -4.37647852e-01]\n",
      " [-1.59009336e+00  3.29526547e-02 -3.63414445e-01 -7.71130601e-02\n",
      "  -2.86605032e-02  8.38130817e-02 -1.83979156e-01 -3.89402141e-01\n",
      "   2.22898268e-01  3.22987947e-02 -3.98947153e-01  2.47173423e-01\n",
      "   1.98393174e-01  9.15065941e-02  3.96398663e-02  1.92748394e-01\n",
      "   1.86843361e-01  7.40554945e-03 -2.62773168e-03 -4.33970526e-02\n",
      "   2.99299410e-01 -1.26203715e-03 -5.82744103e-02  2.14957977e-01\n",
      "   1.15380984e-01  1.58966406e-02  6.85389979e-02  3.39301699e-02\n",
      "  -7.44817166e-02 -6.18378836e-02  1.21586038e-01 -2.85593036e-02\n",
      "  -6.73152235e-02 -2.50491671e-01  2.11130488e-02  9.79615653e-03\n",
      "  -8.32199234e-02 -8.52359286e-03 -5.95128158e-02 -1.83754821e-01\n",
      "  -1.42468267e-01 -1.37028097e-01 -1.43859174e-02  9.72614219e-02\n",
      "   4.93522913e-02  1.75307083e-02  3.31803673e-03  1.87974873e-02\n",
      "   3.05091957e-02  7.23585598e-03  4.15634091e-02  1.32698633e-02\n",
      "   2.89950610e-01  2.11855022e-01]\n",
      " [ 3.04018645e+00 -6.49396694e-02 -8.89899033e-02 -3.52838856e-01\n",
      "  -4.36910379e-02  7.70869292e-02  2.73951295e-02 -9.81395593e-02\n",
      "  -1.08149963e-01  4.72665620e-01 -3.66689391e-01  4.59481871e-02\n",
      "  -4.68703832e-02 -4.60901499e-03  9.74536887e-02  3.42914479e-02\n",
      "   3.06328579e-02  1.36418446e-03 -1.17899295e-02  1.51750553e-02\n",
      "  -1.36515012e-01 -1.74940421e-01 -3.74121495e-02 -2.54458083e-01\n",
      "   1.23150980e-02  2.12369015e-03 -7.03159782e-02 -1.38855495e-01\n",
      "  -7.54289432e-04 -9.74359474e-02 -1.25869769e-01  2.62641022e-02\n",
      "  -9.80834257e-02 -1.96880235e-02 -4.42414139e-02 -5.12556583e-02\n",
      "  -1.07692912e-01  5.21596920e-03 -6.36064301e-03  2.50861668e-01\n",
      "   1.46733529e-01 -1.31101071e-01 -2.06826202e-01 -8.91522760e-02\n",
      "   2.84198119e-02  1.39986774e-01  2.75880262e-02  1.53291591e-01\n",
      "   3.35374751e-01  3.68447026e-01  2.36706861e-01 -1.24049813e-01\n",
      "   3.56988424e-01  1.34191453e-01]]\n",
      "Intercept: [ 2.9809831   4.0259326  -1.7009424  -2.03002628 -0.66249382 -1.44861774\n",
      " -1.16483547]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\C25Dante.Cometto\\487_finalproject\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/lreg.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "import joblib\n",
    "\n",
    "# Create a logistic regression model\n",
    "lreg = LogisticRegression(penalty='None', \n",
    "                          dual=False, \n",
    "                          tol=0.0001, \n",
    "                          C=1.0, \n",
    "                          fit_intercept=True, \n",
    "                          intercept_scaling=1, \n",
    "                          class_weight=None,\n",
    "                          random_state=42, \n",
    "                          solver='saga', \n",
    "                          max_iter=100, \n",
    "                          multi_class='multinomial', \n",
    "                          verbose=1, \n",
    "                          warm_start=False, \n",
    "                          n_jobs=None, \n",
    "                          l1_ratio=None)\n",
    "\n",
    "# Train the model on the training data\n",
    "lreg.fit(X_train, y_train)\n",
    "\n",
    "# Print the model's coefficients and intercept\n",
    "print(\"Coefficients:\", lreg.coef_)\n",
    "print(\"Intercept:\", lreg.intercept_)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(lreg,lreg_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[29332 12151    28     0     0     4   853]\n",
      " [10036 45203  1055     2    46   222    97]\n",
      " [    0   633  6023   137     7   351     0]\n",
      " [    0     0   323   144     0    82     0]\n",
      " [    8  1810    69     0    10     2     0]\n",
      " [    0   964  1856    25    21   607     0]\n",
      " [ 1873    36     4     0     0     0  2189]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.69      0.70     42368\n",
      "           2       0.74      0.80      0.77     56661\n",
      "           3       0.64      0.84      0.73      7151\n",
      "           4       0.47      0.26      0.34       549\n",
      "           5       0.12      0.01      0.01      1899\n",
      "           6       0.48      0.17      0.26      3473\n",
      "           7       0.70      0.53      0.60      4102\n",
      "\n",
      "    accuracy                           0.72    116203\n",
      "   macro avg       0.55      0.47      0.49    116203\n",
      "weighted avg       0.70      0.72      0.71    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now check results\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "lreg = joblib.load(lreg_filename)\n",
    "\n",
    "y_pred = lreg.predict(X_test)\n",
    "\n",
    "# confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "\n",
    "# For a ROC... multiclass is more complicated\n",
    "# Several methods, choosing Micro-Averaged for best overall summary\n",
    "probs = lreg.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# # Binarize the true labels\n",
    "# classes = np.unique(y_test)\n",
    "# y_true_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# # Compute micro-average ROC\n",
    "# fpr, tpr, thresholds = roc_curve(y_true_binarized.ravel(), probs.ravel())\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# # Plot the micro-averaged ROC curve\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, label=f\"Micro-Averaged ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Diagonal line\n",
    "\n",
    "# Select meaningful indices to annotate\n",
    "# key_indices = [0, len(fpr) // 3, len(fpr) // 2, len(fpr) *2 // 3, len(fpr) *5 // 6, len(fpr) - 1]\n",
    "\n",
    "# for i in key_indices:\n",
    "#     plt.annotate(f'Thresh={thresholds[i]:.2f}',\n",
    "#                  xy=(fpr[i], tpr[i]),\n",
    "#                  xytext=(fpr[i] + 0.1, tpr[i] - 0.1),  # Offset to avoid overlap\n",
    "#                  arrowprops=dict(arrowstyle=\"->\", color='black'),\n",
    "#                  fontsize=10)\n",
    "\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel(\"False Positive Rate\")\n",
    "# plt.ylabel(\"True Positive Rate\")\n",
    "# plt.title(\"Micro-Averaged ROC Curve\")\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Then, can choose a different threshold -- it doesn't use thresholds\n",
    "# threshold = 0.18\n",
    "# y_pred2 = (probs >= threshold).astype(int)\n",
    "\n",
    "# # confusion matrix\n",
    "# confusion = confusion_matrix(y_test, y_pred2)\n",
    "\n",
    "# # classification report\n",
    "# classification_rep = classification_report(y_test, y_pred2)\n",
    "\n",
    "# print(\"Confusion Matrix:\\n\", confusion)\n",
    "# print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
